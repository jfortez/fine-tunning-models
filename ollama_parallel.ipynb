{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4cb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de 10 prompts diferentes para enviar a Ollama\n",
    "prompts = [\n",
    "    \"Explica qué es la computación cuántica en una oración.\",\n",
    "    \"Describe la historia de la inteligencia artificial brevemente.\",\n",
    "    \"Cuáles son los beneficios del procesamiento paralelo?\",\n",
    "    \"¿Qué es el aprendizaje automático?\",\n",
    "    \"¿Cómo funciona un modelo de lenguaje grande?\",\n",
    "    \"Explica la diferencia entre CPU y GPU.\",\n",
    "    \"¿Qué es la computación en la nube?\",\n",
    "    \"¿Por qué es importante la ciberseguridad?\",\n",
    "    \"¿Qué son las redes neuronales?\",\n",
    "    \"¿Cómo se usa Python en la ciencia de datos?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01845447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import asyncio\n",
    "\n",
    "def query_ollama(prompt):\n",
    "    try:\n",
    "        response = ollama.generate(model=\"llama3.1:8b\", prompt=prompt)\n",
    "        return response[\"response\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error processing prompt '{prompt}': {str(e)}\"\n",
    "\n",
    "async def query_ollama_async(prompt):\n",
    "    try:\n",
    "        response = await ollama.AsyncClient().generate(model=\"llama3.1:8b\", prompt=prompt)\n",
    "        return response[\"response\"]\n",
    "    except Exception as e:\n",
    "        return f\"Error processing prompt '{prompt}': {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Explica qué es la computación cuántica en una oración.\n",
      "Respuesta: La computación cuántica se basa en el funcionamiento de las partículas subatómicas, como los electrones y los átomos que poseen ciertas propiedades cuánticas únicas para procesar grandes cantidades de información mucho más rápido y eficientemente que cualquier computadora clásica.\n",
      "\n",
      "Prompt: Describe la historia de la inteligencia artificial brevemente.\n",
      "Respuesta: La inteligencia artificial (IA) es un campo en constante evolución que abarca desde sus orígenes hasta las aplicaciones modernas que transforman nuestra vida cotidiana.\n",
      "\n",
      "### Orígenes: 1950s - 1970s\n",
      "\n",
      "*   **Cerebro Digital y Lógica**: El inicio de la IA se remonta a finales de los años 50 con la creación del \"Computador Cerebral\" por Alan Turing, quien propuso el test de Turing como una forma de determinar si un dispositivo artificial podría pensar. A su vez, el modelo de computación logico-deductivo de Marvin Minsky y Seymour Papert en los años sesenta se centró en la capacidad para deducir conclusiones lógicas.\n",
      "*   **Redes Neuronales Artificiales (RNAs)**: En 1958, Frank Rosenblatt desarrolló una red neuronal artificial. Pero fue en el año 1969 cuando Marvin Minsky y Seymour Papert publicaron su trabajo sobre la teoría de redes neuronales artificiales, que se centró en las capacidades computacionales.\n",
      "*   **Programación del Lenguaje Natural (PLN)**: En los años setenta, comenzaron a surgir investigaciones sobre PLN, con énfasis en la capacidad para comprender y generar lenguaje natural.\n",
      "\n",
      "### Avances: 1980s - 1990s\n",
      "\n",
      "*   **Aprendizaje Automático**: El término \"aprendizaje automático\" (Machine Learning, ML) se popularizó durante esta época, con el objetivo de desarrollar sistemas capaces de mejorar sus propias habilidades a través del aprendizaje de datos.\n",
      "*   **Redes Neuronales Artificiales Evolucionarias**: Las redes neuronales evolutivas, un tipo de algoritmo genético que optimiza la configuración de las redes neuronales, se convirtieron en un área de investigación intensa.\n",
      "\n",
      "### Era Digital: 2000s - Actualidad\n",
      "\n",
      "*   **Aprendizaje Automático con Redes Neuronales Profundas (RNP)**: El resurgimiento de los RNP en el siglo XXI ha sido impulsado por la capacidad para procesar grandes cantidades de datos y su aplicación en diversas áreas, desde la visión artificial hasta el reconocimiento de voz.\n",
      "*   **Inteligencia Artificial Amplificada por la Nube**: Las capacidades computacionales cada vez mayores disponibles a través de la nube han permitido una mayor escalabilidad en el procesamiento de datos.\n",
      "\n",
      "Prompt: Cuáles son los beneficios del procesamiento paralelo?\n",
      "Respuesta: El procesamiento paralelo se basa en la capacidad de realizar varias tareas al mismo tiempo, lo que permite aumentar la velocidad y eficiencia. Este proceso no implica una mayor complejidad en la lógica del programa ni requerimientos mayores de memoria. Entre los beneficios del procesamiento paralelo se encuentran: \n",
      "\n",
      "Un aumento significativo en el rendimiento general del sistema.\n",
      "No afecta a las características y funcionalidades básicas del ordenador.\n",
      "No requiere de mayor capacidad de almacenamiento, por lo que su implementación es más barata.\n",
      "\n",
      "Prompt: ¿Qué es el aprendizaje automático?\n",
      "Respuesta: El aprendizaje automático (Machine Learning, ML) es un subconjunto de la inteligencia artificial que implica el diseño y entrenamiento de algoritmos para identificar patrones en datos estadísticos. El propósito principal del aprendizaje automático es desarrollar modelos informáticos capaces de tomar decisiones o predecir resultados basándose en los patrones y relaciones observadas en grandes conjuntos de datos.\n",
      "\n",
      "Prompt: ¿Cómo funciona un modelo de lenguaje grande?\n",
      "Respuesta: Los modelos de lenguaje grandes como LLaMA, BERT, RoBERTa y otros están diseñados para procesar y entender el lenguaje natural de una manera similar a cómo lo hace un humano. A continuación, se describe su funcionamiento en general.\n",
      "\n",
      "Un modelo de lenguaje grande consta de varias capas (o capas de procesamiento) que trabajan juntas para realizar tareas como la traducción de idiomas, el resumen automático, la clasificación de texto y generar texto. A continuación, te explico los conceptos generales sobre cómo funcionan estos modelos.\n",
      "\n",
      "1.  **Entrada del Lenguaje:** Cuando se proporciona una entrada (por ejemplo, un párrafo o oración), el modelo convierte esa cadena de caracteres en una representación numérica llamada \"vector de entrada\". Este vector tiene varias dimensiones, lo que permite al modelo capturar sutilezas y relaciones entre las palabras.\n",
      "\n",
      "2.  **Capas de Procesamiento:** El vector de entrada pasa por varias capas de procesamiento, cada una diseñada para extraer diferentes características del lenguaje natural. Estas capas pueden ser:\n",
      "\n",
      "    -   **Capa de atención**: Esta capa permite al modelo prestar más atención a ciertas partes de la secuencia de entrada que son más relevantes para el problema específico.\n",
      "\n",
      "    -   **Capa recurrente (RNN) o Capa de procesamiento de Lenguaje Profundo (Transformers)**: Estas capas permiten que el modelo aprenda patrones y relaciones en el lenguaje natural a través de la secuencia de entradas. Las capas RNN procesan las secuencias uno paso a la vez, mientras que las capas de Transformers tratan toda la secuencia simultáneamente.\n",
      "\n",
      "3.  **Capa de Clasificación (opcional):** Dependiendo del problema, puede haber una capa adicional para realizar tareas como clasificar un texto en una categoría específica o identificar el sentimiento detrás de una oración.\n",
      "\n",
      "4.  **Salida:** Finalmente, el modelo genera una salida basada en la información procesada por las capas anteriores. Si se trata de una tarea de clasificación, la salida será la categoría más probable para la entrada. Si es un modelo de secuencia a secuencia como seq2seq, la salida serán las palabras o tokens predichos.\n",
      "\n",
      "5.  **Entrenamiento del Modelo:** Los modelos de lenguaje grandes se entrenan en grandes conjuntos de datos con técnicas de optimización como gradientes descendientes y aprendizaje por refuerzo. Esto permite al modelo aprender patrones, relaciones y reglas del lenguaje natural para producir predicciones precisas.\n",
      "\n",
      "6.  **Evaluación:** Una vez entrenado el modelo, se evalúa su rendimiento utilizando conjuntos de pruebas y métricas como precisión, recall y F1-score.\n",
      "\n",
      "Prompt: Explica la diferencia entre CPU y GPU.\n",
      "Respuesta: Ambas son unidades procesadoras de computadora, pero tienen un uso específico en las diferentes tareas realizadas por la computadora.\n",
      "\n",
      "**CPU (Unidad Central de Procesamiento)**: La CPU es el corazón de cualquier ordenador y se encarga de realizar cálculos básicos como sumar, restar, multiplicar o dividir. También gestiona todo lo relacionado con los datos almacenados en la memoria RAM, como leerlos y escribirles. Para procesar información compleja y visualizarla requiere una gran cantidad de computación que no es posible hacerlo mediante solo CPU.\n",
      "\n",
      "**GPU (Unidad de Procesamiento Gráfico)**: La GPU se enfoca principalmente a realizar tareas gráficas para ordenadores, tabletas o cualquier otro dispositivo con pantalla. Se especializa en cálculos matemáticos complejos necesarios para la creación de efectos visuales en juegos y películas, como renderizar imágenes 3D.\n",
      "\n",
      "Puedes utilizar un procesador rápido pero sin una buena GPU no podrás jugar a los últimos juegos más gráficamente exigentes o incluso si puedes jugar se verá ralentizado.\n",
      "\n",
      "Espero que la explicación sea clara y útil.\n",
      "\n",
      "Prompt: ¿Qué es la computación en la nube?\n",
      "Respuesta: Error processing prompt '¿Qué es la computación en la nube?': Server disconnected without sending a response.\n",
      "\n",
      "Prompt: ¿Por qué es importante la ciberseguridad?\n",
      "Respuesta: Error processing prompt '¿Por qué es importante la ciberseguridad?': Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n",
      "\n",
      "Prompt: ¿Qué son las redes neuronales?\n",
      "Respuesta: Error processing prompt '¿Qué son las redes neuronales?': Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n",
      "\n",
      "Prompt: ¿Cómo se usa Python en la ciencia de datos?\n",
      "Respuesta: Error processing prompt '¿Cómo se usa Python en la ciencia de datos?': Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n",
      "\n",
      "Tiempo total de ejecución: 556.78 segundos\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for prompt in prompts:\n",
    "  result = query_ollama(prompt)\n",
    "  print(f\"\\nPrompt: {prompt}\\nRespuesta: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Explica qué es la computación cuántica en una oración.\n",
      "Respuesta: La computación cuántica es un tipo de procesamiento de datos que utiliza las propiedades de los sistemas cuánticos para realizar cálculos más rápidos y eficientes que aquellos realizados por computadoras tradicionales.\n",
      "\n",
      "Prompt: Describe la historia de la inteligencia artificial brevemente.\n",
      "Respuesta: La historia de la inteligencia artificial (IA) es un campo en constante evolución que se remonta a principios del siglo XX. A continuación, te presento una visión general breve:\n",
      "\n",
      "1.  **Deshacemos el mito de que la IA era algo reciente**: La IA comenzó como una rama de las matemáticas y la informática en la década de 1950.\n",
      "\n",
      "2.  **El nacimiento de la IA (1956)**: En la Universidad de Dartmouth, John McCarthy ayudó a lanzar el primer curso sobre Inteligencia Artificial. \n",
      "\n",
      "3.  **Los sistemas expertos**: Después de que la AI sufriera una crisis en la década de los años 70 y 80 debido al limitado progreso, se desarrollaron los sistemas expertos. Estos eran programas diseñados para realizar tareas específicas con un alto nivel de experticia. Los sistemas expertos permitieron mejorar la productividad en varios ámbitos, como la medicina, la ingeniería y el mantenimiento.\n",
      "\n",
      "4.  **La revolución del procesamiento del lenguaje natural (PNL)**: A partir de la década de los años 90, se comenzó a trabajar intensamente en sistemas que pudiesen entender y generar lenguaje humano de manera más eficiente y precisa. El PNL es una rama de la IA enfocada en el procesamiento automático del lenguaje natural.\n",
      "\n",
      "5.  **La era de las redes neuronales (NN)**: A principios de los años 2000, se volvieron populares las redes neuronales artificiales como modelos para aprender patrones y datos complejos. Las redes neuronales son inspiradas en la estructura del cerebro humano, pero están diseñadas de manera muy diferente.\n",
      "\n",
      "6.  **El auge de la IA aplicada**: En la década de los años 2010 hasta 2023, se comenzó a desarrollar una variedad de herramientas y servicios basados en IA para múltiples industrias y sectores. Estos incluyen inteligencia artificial enfocada a la automatización de tareas repetitivas, el reconocimiento facial y la voz, así como la optimización de procesos.\n",
      "\n",
      "7.  **La era actual de la IA**: Hoy en día, se continua investigando sobre nuevas técnicas y tecnologías en el campo de la IA, como la inteligencia artificial simbólica, el aprendizaje automático y las redes neuronales profundas. Se está trabajando para que los modelos de IA sean más precisos, escalables y confiables.\n",
      "\n",
      "Esto es un resumen muy breve sobre la historia de la inteligencia artificial, pero espero que te haya ayudado a entender cómo ha evolucionado el campo en las últimas décadas.\n",
      "\n",
      "Prompt: Cuáles son los beneficios del procesamiento paralelo?\n",
      "Respuesta: El procesamiento paralelo ofrece varias ventajas en términos de velocidad y eficiencia. Al ejecutar varias tareas simultáneamente, se reducen significativamente los tiempos de computación y mejora la capacidad para manejar grandes cantidades de datos. Además, permite una mayor escalabilidad y flexibilidad, lo que facilita el desarrollo de soluciones más complejas y personalizadas.\n",
      "\n",
      "Prompt: ¿Qué es el aprendizaje automático?\n",
      "Respuesta: El aprendizaje automático es un campo de la inteligencia artificial (IA) que implica a las computadoras para aprender con base en los datos y mejorar su desempeño sin necesidad de ser programadas explícitamente. Los algoritmos de aprendizaje automático se pueden entrenar usando grandes conjuntos de datos con características o etiquetas asociados a ellas, lo cual permite a las computadoras generalizar y hacer predicciones sobre nuevos datos que no han sido vistos antes.\n",
      "Los objetivos del Aprendizaje Automático varían ampliamente, desde clasificación y regresión hasta detección de anomalías, clustering o generación de texto.\n",
      "\n",
      "Prompt: ¿Cómo funciona un modelo de lenguaje grande?\n",
      "Respuesta: Un modelo de lenguaje grande como BERT es una red neuronal profunda entrenada sobre grandes cantidades de texto para realizar tareas de procesamiento del lenguaje natural. Funciona mediante el siguiente procedimiento:\n",
      "\n",
      "1.  **Toma de datos**: El modelo se entrena con un conjunto de textos enormes, que pueden ser libros, artículos o cualquier otra fuente de texto.\n",
      "2.  **Preprocesamiento de datos:** Luego los datos son preprocesados para convertirlos en una secuencia de vectores numéricos, mediante técnicas como tokenización y embeddings (representaciones numéricas de palabras y tokens).\n",
      "3.  **Entrenamiento**: El modelo se entrena con estas secuencias de vectores a través de técnicas de aprendizaje automático, como retropropagación en adelante y atrás.\n",
      "4.  **Predicción:** Una vez entrenado, el modelo puede ser utilizado para realizar tareas de procesamiento del lenguaje natural, como traducción automática, análisis de sentimiento, detección de entidades nombradas o síntesis de texto.\n",
      "\n",
      "5.  **Evaluación:** El desempeño del modelo se evalúa mediante métricas como precisión y recall, para asegurarse que el modelo esté funcionando correctamente en tareas específicas.\n",
      "\n",
      "Los modelos de lenguaje grandes pueden realizar una amplia gama de tareas, incluyendo:\n",
      "\n",
      "*   Traducción automática: El modelo puede traducir texto de un idioma a otro con gran precisión.\n",
      "*   Análisis de sentimiento: El modelo puede analizar el tono y la emoción en un texto, identificando si es positivo o negativo.\n",
      "*   Detección de entidades nombradas (NER): El modelo puede detectar y clasificar entidades como nombres propios, fechas, ubicaciones, etc.\n",
      "\n",
      "El proceso de entrenamiento y ajuste de los modelos de lenguaje grandes a menudo se realiza mediante herramientas de machine learning como TensorFlow o PyTorch.\n",
      "\n",
      "Prompt: Explica la diferencia entre CPU y GPU.\n",
      "Respuesta: La principal diferencia entre CPU (Unidad Central de Procesamiento) y GPU (Unidad de Gráficos, en español) se encuentra en su función específica dentro del hardware computacional.\n",
      "\n",
      "- **CPU**: La CPU es el corazón del ordenador. Es la que ejecuta las instrucciones del software para procesar datos. Su función principal es realizar tareas matemáticas y lógicas complejas de forma rápida, como la ejecución de programas, gestión de memoria, manejo de instrucciones e incluso comprender el lenguaje del software. Se centra en hacer que las operaciones sean eficientes en general y no necesariamente son específicas para el procesamiento visual.\n",
      "\n",
      "- **GPU**: La GPU está diseñada principalmente para realizar tareas que involucren gran cantidad de cálculos matemáticos y especialmente la aceleración de procesos gráficos, pero también puede ser utilizada para otros tipos de procesamiento en paralelo. Una de sus principales funciones es mejorar las experiencias visuales en videojuegos o aplicaciones que requieren renderización 3D intensiva. Las GPU están diseñadas específicamente para manejar muchas operaciones en paralelo, haciendo posible un rendimiento impresionante en tareas computacionales.\n",
      "\n",
      "En resumen: La CPU se enfoca en el procesamiento general de instrucciones y es la parte lógica del ordenador, mientras que la GPU se centra en el procesamiento visual (como gráficos 3D) y también puede ser utilizada para otras tareas que necesiten grandes cantidades de cálculos matemáticos.\n",
      "\n",
      "Prompt: ¿Qué es la computación en la nube?\n",
      "Respuesta: La computación en la nube se refiere a modelos de entrega y consumo de servicios de TI que pueden accederse mediante Internet, ya sean de forma gratuita o por una tarifa. Algunos ejemplos son Microsoft Azure, Google Cloud Platform y Amazon Web Services (AWS).\n",
      "\n",
      "Prompt: ¿Por qué es importante la ciberseguridad?\n",
      "Respuesta: La importancia de la ciberseguridad radica en que protege a las personas, organizaciones y gobiernos de daños potenciales causados por el hacking. Esto incluye robo de datos confidenciales, extorsión e incluso manipulación del sistema informático.\n",
      "\n",
      "Prompt: ¿Qué son las redes neuronales?\n",
      "Respuesta: Las Redes Neuronales (RN) son modelos de inteligencia artificial inspirados en la forma en que funcionan el cerebro humano y los nervios del cuerpo. Están compuestas por varias capas de procesos de computación, similares a las células cerebrales o neuronas. Funcionan mediante un proceso complejo denominado aprendizaje automático, en el que se ajustan para predecir resultados basándose en datos.\n",
      "\n",
      "Las RN pueden aprender y mejorar con la experiencia, lo que les permite resolver problemas complejos de manera precisa. Existen varios tipos de redes neuronales, incluyendo las redes neuronales artificiales (AN), los sistemas expertos y las redes neuronales profundas (DNN).\n",
      "\n",
      "Prompt: ¿Cómo se usa Python en la ciencia de datos?\n",
      "Respuesta: Python es una de las herramientas más populares utilizadas en la ciencia de datos debido a su simplicidad, flexibilidad y potencial de creación de aplicaciones. Los siguientes son algunos ejemplos de cómo se utiliza Python en ciencia de datos:\n",
      "\n",
      "1.  **Análisis de Datos**: Para el análisis de los conjuntos de datos, utilizando bibliotecas como Pandas para la manipulación y análisis de grandes conjuntos de datos, NumPy para operaciones matemáticas vectoriales, y Matplotlib o Seaborn para visualizar los resultados.\n",
      "2.  **Modelado Predictivo**: Para el modelado predictivo, utilizando bibliotecas como Scikit-learn o TensorFlow para entrenar modelos de aprendizaje automático (Machine Learning) que puedan predecir nuevos valores a partir de conjuntos de datos.\n",
      "3.  **Minería de Datos**: Para la minería de datos, se utiliza Python en conjunto con las bibliotecas Pandas y NumPy para limpieza y análisis de los datos, Scikit-learn o TensorFlow para el entrenamiento de modelos predictivos y Matplotlib o Seaborn para visualizar los resultados.\n",
      "4.  **Visualización**: Para la visualización de los datos, utilizando bibliotecas como Matplotlib o Seaborn que permiten crear gráficos personalizados, visualizando datos en diferentes tipos de gráficos como gráficas de barras, líneas, puntos, dispersión entre otros.\n",
      "5.  **Scraping Web**: Para el scraping web, Python utiliza una biblioteca llamada BeautifulSoup que permite extraer información de sitios web.\n",
      "6.  **Aprendizaje Automático**: Para el aprendizaje automático se utilizan las bibliotecas Scikit-learn y TensorFlow que permiten entrenar modelos predictivos como clasificadores, regresores, clustering entre otros.\n",
      "\n",
      "Python ofrece una amplia gama de herramientas y recursos para trabajar en la ciencia de datos. Por lo tanto, su conocimiento es crucial para quienes deseen contribuir a este campo.\n",
      "\n",
      "Tiempo total de ejecución: 270.87 segundos\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(query_ollama, prompts))\n",
    "    \n",
    "for prompt, result in zip(prompts, results):\n",
    "    print(f\"\\nPrompt: {prompt}\\nRespuesta: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b7add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Explica qué es la computación cuántica en una oración.\n",
      "Respuesta: La computación cuántica es un tipo de procesamiento de datos que utiliza el comportamiento cuántico, como superposiciones y entrelazamientos, para realizar cálculos más rápido y eficiente que los sistemas clásicos.\n",
      "\n",
      "Prompt: Describe la historia de la inteligencia artificial brevemente.\n",
      "Respuesta: La historia de la Inteligencia Artificial (IA) es larga y compleja, pero te presento una visión general en varias etapas clave:\n",
      "\n",
      "1. **Inicios:**\n",
      "   - La IA se originó en la década de 1950 con las investigaciones de Alan Turing, quien lanzó el Test de Turing para determinar si una máquina podía comportarse como un ser humano.\n",
      "   - En los años 60 y 70, la comunidad científica comenzó a explorar cómo crear sistemas capaces de razonamiento automático.\n",
      "\n",
      "2. **Auge en la década de 1980:**\n",
      "   - La IA se convirtió en una tendencia importante en la década de 1980 con el surgimiento del Proyecto de Inteligencia Artificial (DARPA) y el trabajo de investigadores como John McCarthy, Marvin Minsky, y Seymour Papert.\n",
      "   - Durante esta época, los expertos trabajaron para desarrollar sistemas que pudieran aprender y mejorar sus habilidades.\n",
      "\n",
      "3. **Pérdida de interés y recesión (1980-2000):**\n",
      "   - A medida que los proyectos de IA no alcanzaban las expectativas, el interés en la disciplina disminuyó.\n",
      "   - La creencia de que la IA sería capaz de resolver todos los problemas se desvaneció, y algunos expertos criticaron lo que consideraban un exceso de optimismo.\n",
      "\n",
      "4. **Resurgimiento en la era digital (2000-presente):**\n",
      "   - Con el auge del internet y las redes sociales, los datos comenzaron a multiplicarse, creando una oportunidad para el regreso de la IA.\n",
      "   - Los avances en el procesamiento de lenguaje natural, aprendizaje automático profundo y visión artificial revitalizaron la disciplina.\n",
      "\n",
      "5. **Actualidad:**\n",
      "   - En la actualidad, la IA se utiliza cada vez más en diversas áreas como inteligencia financiera, reconocimiento facial, transporte autónomo y asistentes virtuales.\n",
      "   - Sin embargo, también surgen preocupaciones sobre la seguridad, privacidad y el potencial de uso indebido de la tecnología.\n",
      "\n",
      "La historia de la Inteligencia Artificial es un reflejo del avance continuo de las tecnologías y la capacidad humana para enfrentar nuevos desafíos con innovación.\n",
      "\n",
      "Prompt: Cuáles son los beneficios del procesamiento paralelo?\n",
      "Respuesta: El procesamiento en paralelo es un concepto fundamental de la informática que permite aumentar el rendimiento de una computadora al mismo tiempo que se reduce su costo. Este proceso implica utilizar múltiples unidades centrales de procesamiento (CPU) o núcleos para realizar tareas simultáneamente y en paralelo, en lugar de utilizar solo un CPU.\n",
      "\n",
      "Los beneficios del procesamiento en paralelo son:\n",
      "\n",
      "1.  **Mejora significativa del rendimiento**: El procesamiento en paralelo permite que varias tareas se ejecuten al mismo tiempo, lo que aumenta la velocidad general del sistema y mejora el rendimiento.\n",
      "2.  **Mayor escalabilidad**: Las computadoras con múltiples CPUs pueden escalar mejor para manejar grandes cantidades de datos o tareas complejas, mientras que las sistemas monopuerto no necesariamente mejoran su desempeño cuando se incrementa la cantidad de procesadores.\n",
      "3.  **Reducción del tiempo de respuesta**: Debido a que múltiples procesos pueden ejecutarse simultáneamente, el tiempo de respuesta para los usuarios se reduce significativamente.\n",
      "4.  **Disminución del tiempo de computación**: Las computadoras con múltiples CPUs y procesamiento en paralelo pueden realizar cálculos más complejos, como algoritmos científicos o simulaciones, en un tiempo mucho menor que las computadoras con procesamiento único.\n",
      "\n",
      "5.  **Mayor confiabilidad**: El procesamiento en paralelo permite que si una CPU falla o se vuelve inoperativa, la computadora puede seguir funcionando normalmente debido a que otras CPUs pueden asumir el trabajo de la CPU fallida.\n",
      "6.  **Facilidad de mantenimiento y actualización**: Las computadoras con múltiples CPUs son más fáciles de mantener y actualizar porque si una CPU falla se debe reemplazar solo esa, en lugar de toda la CPU.\n",
      "\n",
      "En resumen, el procesamiento en paralelo permite aumentar el rendimiento de las computadoras al mismo tiempo que reduce su costo.\n",
      "\n",
      "Prompt: ¿Qué es el aprendizaje automático?\n",
      "Respuesta: El aprendizaje automático, también conocido como Inteligencia artificial (IA), se refiere a las técnicas utilizadas por las computadoras para aprender de los datos y mejorar sus procesos en lugar de seguir un algoritmo predefinido. Se divide en dos áreas: el Aprendizaje supervisado y no supervisado.\n",
      "\n",
      "Prompt: ¿Cómo funciona un modelo de lenguaje grande?\n",
      "Respuesta: Un modelo de lenguaje grande, como el modelo Llama del que estoy basado, está diseñado para comprender y generar texto. Funciona mediante una serie de capas procesadoras de información (red neuronal) que permiten a la inteligencia artificial realizar varias tareas:\n",
      "\n",
      "1. **Leer y entender**: El modelo puede leer un conjunto de palabras o tokens e identificar relaciones entre ellos. Esto se logra a través de técnicas como el embeddings, donde cada palabra es representada por un vector numérico que captura su significado.\n",
      "\n",
      "2. **Analizar contexto**: A partir del análisis del texto proporcionado, el modelo puede comprender el contexto en el que las palabras son utilizadas. Esto incluye identificar la intención o acción descrita en el texto y cómo sus elementos están relacionados entre sí.\n",
      "\n",
      "3. **Generar respuesta**: Después de entender el contexto, el modelo utiliza su capacidad de razonamiento para generar una respuesta apropiada al texto proporcionado. Esto implica seleccionar palabras y estructurarlas en un sentido lógico que refleje la comprensión del modelo.\n",
      "\n",
      "El proceso es bastante complejo y requiere entrenamiento con grandes cantidades de datos, algo que se lleva a cabo antes del uso del modelo. \n",
      "\n",
      "Tanto el procesamiento de texto como la generación de respuesta son fundamentales en modelos de lenguaje como Llama, y permiten al modelo realizar diversas tareas, desde responder preguntas hasta generar historias o incluso traducir idiomas.\n",
      "\n",
      "Prompt: Explica la diferencia entre CPU y GPU.\n",
      "Respuesta: La principal diferencia entre CPU (Central Processing Unit) y GPU (Graphics Processing Unit), es que la primera procesa datos numéricos mientras que la segunda procesa imágenes y videos.\n",
      "\n",
      "Prompt: ¿Qué es la computación en la nube?\n",
      "Respuesta: La computación en la nube es un modelo de servicios donde los recursos y aplicaciones se almacenan y entregan a través de internet. Los proveedores de servicios de cloud como Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP) y IBM Cloud ofrecen una variedad de productos y servicios para satisfacer las necesidades de desarrollo y producción del usuario.\n",
      "\n",
      "Prompt: ¿Por qué es importante la ciberseguridad?\n",
      "Respuesta: La ciberseguridad es importante porque ayuda a proteger información confidencial y prevenir ataques de hackers. La seguridad en línea impide el acceso no autorizado a datos personales o sensibles, como números de tarjeta de crédito o secretarias bancarias. Además, puede impedir que los usuarios accedan ilegalmente al sistema informático.\n",
      "\n",
      "Prompt: ¿Qué son las redes neuronales?\n",
      "Respuesta: Las redes neuronales son sistemas de computación inspirados en el cerebro humano, que están compuestos por capas interconectadas de \"nodos\" o \"neuronas\" artificiales. Estos nodos pueden tomar varias entradas, aplicarles una función y producir una salida.\n",
      "\n",
      "Prompt: ¿Cómo se usa Python en la ciencia de datos?\n",
      "Respuesta: Python es ampliamente utilizado en la comunidad de Ciencia de Datos debido a su facilidad de uso, flexibilidad y bibliotecas extendidas. A continuación, te muestro algunos de los aspectos más relevantes:\n",
      "\n",
      "1.  **Análisis de datos**: Python tiene varias bibliotecas para el análisis de datos como NumPy (cálculo numérico) y Pandas (manejo de tablas y series temporales).\n",
      "2.  **Visualización de datos**: Gráficas y mapas en diferentes formatos se pueden visualizar mediante librerías como Matplotlib, Seaborn y Plotly.\n",
      "3.  **Modelado predictivo**: Bibliotecas como Scikit-learn (aprendizaje automático) permiten la creación de modelos de aprendizaje supervisado e no supervisado para realizar predicciones basadas en datos.\n",
      "4.  **Interfaz con bases de datos**: Se pueden utilizar bibliotecas como SQLite, MySQL-connector-python y psycopg2 para interactuar con bases de datos SQL y NoSQL.\n",
      "5.  **Programación orientada a objetos (OOP)**: Python es un lenguaje con soporte nato para la OOP, lo que permite a los usuarios crear clases personalizadas para encapsular datos y métodos relacionados con ellos.\n",
      "6.  **Desarrollo de algoritmos**: Es posible escribir desde algoritmos simples hasta complejos sistemas de inteligencia artificial en Python, facilitando el desarrollo de aplicaciones innovadoras.\n",
      "\n",
      "Algunas de las herramientas más populares utilizadas en la Ciencia de Datos con Python incluyen:\n",
      "\n",
      "*   Jupyter Notebooks: Una plataforma que permite experimentar y visualizar resultados interactivamente.\n",
      "*   Anaconda: Un entorno de desarrollo para ciencia de datos que incluye varios paquetes, como NumPy, SciPy y Matplotlib.\n",
      "*   TensorFlow y PyTorch: Bibliotecas utilizadas para desarrollar redes neuronales artificiales (RNA) en Python.\n",
      "\n",
      "En resumen, la flexibilidad y el amplio conjunto de herramientas disponibles lo convierten a Python en una elección popular para proyectos de Ciencia de Datos.\n",
      "\n",
      "Tiempo total de ejecución: 237.61 segundos\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "async def main():\n",
    "    tasks = [query_ollama_async(prompt) for prompt in prompts]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    for prompt, result in zip(prompts, results):\n",
    "        print(f\"\\nPrompt: {prompt}\\nRespuesta: {result}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTiempo total de ejecución: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540e7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
