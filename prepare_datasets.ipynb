{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067529bb",
   "metadata": {},
   "source": [
    "# Generacion de Datasets utilizando RLHF para fine tunning\n",
    "\n",
    "## Procedimiento\n",
    "\n",
    "- Recoleccion de Datos: Obtener Informacion mediante documentos de textos seleccionables (no escaneados), mediante web, redes sociales, scrapping,etc\n",
    "- Extraer Texto: Usa PyMuPDF para extraer texto de PDFs no escaneados, procesando en paralelo con ProcessPoolExecutor para manejar grandes volúmenes (>100, >10,000).\n",
    "- Limpiar Datos: Elimina espacios múltiples y caracteres no deseados con expresiones regulares, asegurando texto coherente.\n",
    "- Validar: Verifica que los fragmentos extraídos no estén vacíos y tengan una longitud mínima (por ejemplo, 50 caracteres).\n",
    "- Generar Conversaciones: Divide el texto en párrafos, usa un modelo como meta-llama/Llama-3.2-1B-Instruct para generar diálogos conversacionales específicos al contenido, con al menos 4 intercambios por conversación, en formato {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}], \"topic\": \"...\"}.\n",
    "- Estructurar Dataset: Guarda las conversaciones en archivos JSONL con dos columnas: \"messages\" y \"topic\".\n",
    "Cargar y Subir: Carga el dataset con load_dataset(\"json\", data_files=\"path/*.jsonl\") y súbelo a un repositorio privado en Hugging Face Hub con push_to_hub(\"username/dataset_name\", private=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa351d6-c527-423f-9d2e-417d0ef2b8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45295ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in ./venv/lib/python3.11/site-packages (1.26.3)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: ollama in ./venv/lib/python3.11/site-packages (0.5.1)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from nltk) (8.2.2)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.11/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.11/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: httpx>=0.27 in ./venv/lib/python3.11/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in ./venv/lib/python3.11/site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.11/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.27->ollama) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.11/site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./venv/lib/python3.11/site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.11/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pymupdf nltk ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4760f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MIN_FRAGMENT_LENGTH = 500  # Longitud mínima de un fragmento\n",
    "MAX_FRAGMENT_LENGTH = 2000  # Longitud máxima de un fragmento\n",
    "REPEAT_THRESHOLD = 0.3  # Umbral para considerar un bloque como repetitivo\n",
    "\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "TEMPERATURE = 0.7  # Equilibrio entre creatividad y coherencia\n",
    "TOP_P = 0.9  # Filtrado de núcleo para diversidad\n",
    "MIN_CONVERSATION_LENGTH = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be033f",
   "metadata": {},
   "source": [
    "### Recoleccion de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b45b0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Folder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Verificar si la carpeta existe\n",
    "\n",
    "folder_url = \"/workspace/data/uploads\"\n",
    "folder = Path(folder_url)\n",
    "\n",
    "\n",
    "if folder.exists() and folder.is_dir():\n",
    "    print(\"Valid Folder\")\n",
    "    \n",
    "# Obtener todos los archivos de la carpeta\n",
    "files = [f for f in folder.rglob(\"*\") if f.is_file()]\n",
    "\n",
    "files\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4f060",
   "metadata": {},
   "source": [
    "### Extraccion de Texto y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed080bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "import os\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "# Constantes\n",
    "MIN_FRAGMENT_LENGTH = 500\n",
    "MAX_FRAGMENT_LENGTH = 2000\n",
    "REPEAT_THRESHOLD = 0.3\n",
    "MIN_BLOCK_LENGTH = 30  # Reducido de 50 a 30 para incluir bloques más cortos\n",
    "\n",
    "def clean_text(text, repeated_blocks=None):\n",
    "    \"\"\"Limpia el texto, eliminando caracteres repetitivos, texto redundante y caracteres no deseados.\"\"\"\n",
    "    # Eliminar caracteres de control no deseados (excepto \\n)\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', text)\n",
    "    # Eliminar patrones repetitivos como ----, ...., ****\n",
    "    text = re.sub(r'([^\\w\\s])\\1{2,}|\\s*[.]{3,}\\s*', '', text)\n",
    "    # Normalizar espacios múltiples\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    # Eliminar espacios al inicio y final de cada línea\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    # Filtrar líneas duplicadas, números, correos y contenido administrativo\n",
    "    seen_lines = set()\n",
    "    unique_lines = []\n",
    "    for line in lines:\n",
    "        if line not in seen_lines and \\\n",
    "           not re.match(r'^\\d+$', line) and \\\n",
    "           not re.match(r'.*@(.*\\.)+.*', line) and \\\n",
    "           not re.match(r'^(Tel|Fax|E-mail|www\\.).*', line, re.IGNORECASE) and \\\n",
    "           (repeated_blocks is None or line not in repeated_blocks):\n",
    "            unique_lines.append(line)\n",
    "            seen_lines.add(line)\n",
    "    return '\\n'.join(unique_lines)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extrae texto de un PDF en una sola pasada, preservando el texto del inicio de la página,\n",
    "    eliminando encabezados, pies de página y contenido irrelevante,\n",
    "    dividiendo en fragmentos de 500 a 2000 caracteres con metadata corregida.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path)\n",
    "        total_pages = len(doc)\n",
    "        chunks = []\n",
    "        current_chunk = []  # Lista de (párrafo, página)\n",
    "        current_chunk_length = 0\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        block_counter = Counter()\n",
    "\n",
    "        for page_number in range(1, total_pages + 1):\n",
    "            page = doc[page_number - 1]\n",
    "            page_height = page.rect.height\n",
    "            blocks = page.get_text(\"blocks\")\n",
    "            page_text = []\n",
    "\n",
    "            # Procesar bloques y filtrar encabezados/pies de página\n",
    "            for block in blocks:\n",
    "                text = block[4]\n",
    "                y0, y1 = block[1], block[3]\n",
    "                # Excluir pies de página (parte inferior de la página)\n",
    "                if y1 > 0.95 * page_height:  # Relajado de 0.95 a 0.9\n",
    "                    continue\n",
    "                # Excluir encabezados solo si son repetitivos\n",
    "                if y0 < 0.05 * page_height:  # Relajado de 0.05 a 0.1\n",
    "                    block_counter[text] += 1\n",
    "                    if block_counter[text] > total_pages * REPEAT_THRESHOLD:\n",
    "                        continue\n",
    "                if text and len(text) >= MIN_BLOCK_LENGTH:\n",
    "                    block_counter[text] += 1\n",
    "                    page_text.append((text, page_number))\n",
    "\n",
    "            # Si no hay texto válido en la página, continuar\n",
    "            if not page_text:\n",
    "                continue\n",
    "\n",
    "            # Acumular párrafos con su número de página\n",
    "            for paragraph, page in page_text:\n",
    "                current_chunk.append((paragraph, page))\n",
    "                current_chunk_length += len(paragraph) + 2  # +2 por \"\\n\\n\"\n",
    "\n",
    "                # Si el fragmento alcanza la longitud mínima, procesarlo\n",
    "                if current_chunk_length >= MIN_FRAGMENT_LENGTH:\n",
    "                    chunk_text = \"\\n\\n\".join(p for p, _ in current_chunk)\n",
    "                    cleaned_chunk = clean_text(chunk_text, None)\n",
    "                    cleaned_length = len(cleaned_chunk)\n",
    "\n",
    "                    # Obtener el rango de páginas del fragmento\n",
    "                    page_numbers = sorted(set(page for _, page in current_chunk))\n",
    "                    start_page = page_numbers[0] if page_numbers else page_number\n",
    "                    end_page = page_numbers[-1] if page_numbers else page_number\n",
    "\n",
    "                    # Dividir fragmentos largos\n",
    "                    while cleaned_length > MAX_FRAGMENT_LENGTH:\n",
    "                        sub_chunk = cleaned_chunk[:MAX_FRAGMENT_LENGTH]\n",
    "                        last_paragraph_end = sub_chunk.rfind(\"\\n\\n\")\n",
    "                        if last_paragraph_end == -1:\n",
    "                            last_paragraph_end = MAX_FRAGMENT_LENGTH\n",
    "                        chunk_to_add = cleaned_chunk[:last_paragraph_end].strip()\n",
    "\n",
    "                        # Calcular el número de páginas para el subfragmento\n",
    "                        chars_so_far = 0\n",
    "                        sub_chunk_pages = []\n",
    "                        for paragraph, page in current_chunk:\n",
    "                            chars_so_far += len(paragraph) + 2\n",
    "                            if chars_so_far <= last_paragraph_end:\n",
    "                                sub_chunk_pages.append(page)\n",
    "                            else:\n",
    "                                break\n",
    "                        sub_start_page = min(sub_chunk_pages) if sub_chunk_pages else page_number\n",
    "                        sub_end_page = max(sub_chunk_pages) if sub_chunk_pages else page_number\n",
    "\n",
    "                        metadata = (\n",
    "                            f\"# FILENAME: {filename} | CHARACTERS: {len(chunk_to_add)} | \"\n",
    "                            f\"PAGES: {sub_start_page}-{sub_end_page}/{total_pages}\\n\\n\"\n",
    "                        )\n",
    "                        chunks.append((metadata + chunk_to_add, hashlib.md5(chunk_to_add.encode()).hexdigest()))\n",
    "                        cleaned_chunk = cleaned_chunk[last_paragraph_end:].strip()\n",
    "                        cleaned_length = len(cleaned_chunk)\n",
    "\n",
    "                        # Actualizar current_chunk para los párrafos restantes\n",
    "                        remaining_chunk = []\n",
    "                        chars_so_far = 0\n",
    "                        for paragraph, page in current_chunk:\n",
    "                            chars_so_far += len(paragraph) + 2\n",
    "                            if chars_so_far > last_paragraph_end:\n",
    "                                remaining_chunk.append((paragraph, page))\n",
    "                        current_chunk = remaining_chunk\n",
    "                        current_chunk_length = cleaned_length\n",
    "                        page_numbers = sorted(set(page for _, page in current_chunk))\n",
    "                        start_page = page_numbers[0] if page_numbers else page_number\n",
    "\n",
    "                    # Añadir el fragmento completo\n",
    "                    if cleaned_length >= MIN_FRAGMENT_LENGTH:\n",
    "                        metadata = (\n",
    "                            f\"# FILENAME: {filename} | CHARACTERS: {cleaned_length} | \"\n",
    "                            f\"PAGES: {start_page}-{end_page}/{total_pages}\\n\\n\"\n",
    "                        )\n",
    "                        chunks.append((metadata + cleaned_chunk, hashlib.md5(cleaned_chunk.encode()).hexdigest()))\n",
    "                        current_chunk = []\n",
    "                        current_chunk_length = 0\n",
    "\n",
    "                    else:\n",
    "                        current_chunk = [(cleaned_chunk, page_numbers[-1])] if page_numbers else []\n",
    "                        current_chunk_length = cleaned_length\n",
    "\n",
    "        # Añadir el fragmento final si cumple con la longitud mínima\n",
    "        if current_chunk and current_chunk_length >= MIN_FRAGMENT_LENGTH:\n",
    "            chunk_text = \"\\n\\n\".join(p for p, _ in current_chunk)\n",
    "            cleaned_chunk = clean_text(chunk_text, None)\n",
    "            cleaned_length = len(cleaned_chunk)\n",
    "            if cleaned_length >= MIN_FRAGMENT_LENGTH:\n",
    "                page_numbers = sorted(set(page for _, page in current_chunk))\n",
    "                start_page = page_numbers[0] if page_numbers else total_pages\n",
    "                end_page = page_numbers[-1] if page_numbers else total_pages\n",
    "                metadata = (\n",
    "                    f\"# FILENAME: {filename} | CHARACTERS: {cleaned_length} | \"\n",
    "                    f\"PAGES: {start_page}-{end_page}/{total_pages}\\n\\n\"\n",
    "                )\n",
    "                chunks.append((metadata + cleaned_chunk, hashlib.md5(cleaned_chunk.encode()).hexdigest()))\n",
    "\n",
    "        doc.close()\n",
    "\n",
    "        # Filtrar bloques repetitivos y duplicados\n",
    "        repeated_blocks = {text for text, count in block_counter.items() if count > total_pages * REPEAT_THRESHOLD}\n",
    "        final_chunks = []\n",
    "        seen_hashes = set()\n",
    "\n",
    "        for chunk, chunk_hash in chunks:\n",
    "            chunk_text = '\\n'.join(line for line in chunk.splitlines() if not line.startswith('#'))\n",
    "            cleaned_chunk = clean_text(chunk_text, repeated_blocks)\n",
    "            if len(cleaned_chunk) >= MIN_FRAGMENT_LENGTH and chunk_hash not in seen_hashes:\n",
    "                # Actualizar la longitud en la metadata después de la limpieza final\n",
    "                metadata_lines = chunk.splitlines()[0]\n",
    "                metadata = re.sub(r'CHARACTERS: \\d+', f'CHARACTERS: {len(cleaned_chunk)}', metadata_lines)\n",
    "                final_chunks.append(f\"{metadata}\\n\\n{cleaned_chunk}\")\n",
    "                seen_hashes.add(chunk_hash)\n",
    "\n",
    "        return final_chunks if final_chunks else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {pdf_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912cd27",
   "metadata": {},
   "source": [
    "### Generar Conversaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2c9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import AsyncClient\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Definir el esquema Pydantic para la salida estructurada\n",
    "class Message(BaseModel):\n",
    "    role: str = Field(..., pattern=\"^(system|user|assistant)$\")\n",
    "    content: str\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    messages: List[Message] = Field(..., min_items=MIN_CONVERSATION_LENGTH)\n",
    "    topic: str\n",
    "\n",
    "ollama_client = AsyncClient()\n",
    "\n",
    "async def generate_conversation(fragment, temperature=TEMPERATURE, top_p=TOP_P):\n",
    "    \"\"\"\n",
    "    Genera una conversación estructurada en formato JSON usando Ollama, basada en un fragmento de texto.\n",
    "    Optimizado para múltiples iteraciones en la generación de datasets para fine-tuning.\n",
    "    \"\"\"\n",
    "    if not fragment or len(fragment) < MIN_FRAGMENT_LENGTH:\n",
    "        print(f\"Error: Fragmento demasiado corto ({len(fragment)} caracteres).\")\n",
    "        return None\n",
    "\n",
    "    # Extraer el texto sin la metadata (líneas que comienzan con '#')\n",
    "    fragment_content = '\\n'.join(line for line in fragment.splitlines() if not line.startswith('#')).strip()\n",
    "    if len(fragment_content) < MIN_FRAGMENT_LENGTH:\n",
    "        print(f\"Error: Contenido útil del fragmento demasiado corto ({len(fragment_content)} caracteres).\")\n",
    "        return None\n",
    "\n",
    "    # Prompt optimizado para múltiples iteraciones\n",
    "    prompt = f\"\"\"\n",
    "<context>\n",
    "{fragment_content}\n",
    "</context>\n",
    "\n",
    "<instructions>\n",
    "Basándote únicamente en el texto dentro de <context>...</context>, genera una conversación estructurada entre un usuario y un asistente con las siguientes características:\n",
    "\n",
    "1. **Estructura**:\n",
    "   - Genera de {MIN_CONVERSATION_LENGTH} a 8 intercambios (parejas usuario-asistente). Usa 2 intercambios para fragmentos con poco contexto (por ejemplo, listas o títulos cortos) y de 4 a 8 para fragmentos detallados.\n",
    "   - La conversación debe comenzar con una pregunta del usuario que refleje un interés específico en el contenido (por ejemplo, explorar regulaciones bancarias).\n",
    "2. **Preguntas del usuario**:\n",
    "   - Deben ser específicas, relevantes y basadas exclusivamente en el fragmento.\n",
    "   - Evita preguntas genéricas como “¿Cuál es el tema?”, “¿Qué organización se menciona?”, “¿Qué menciona en este fragmento?”  o “¿Cuál es el propósito?”, etc....\n",
    "   - Incluye una mezcla de:\n",
    "     - Preguntas factuales (por ejemplo, “¿Qué requisitos se relajan durante el periodo de transición?”).\n",
    "     - Frases incompletas para completar (por ejemplo, “El periodo de transición para el método IRB básico es...”).\n",
    "     - Preguntas de análisis o inferencia (por ejemplo, “¿Por qué es importante un periodo de transición para los bancos?”).\n",
    "   - Las preguntas deben formar un flujo conversacional lógico, donde cada una se base en la respuesta anterior.\n",
    "3. **Respuestas del asistente**:\n",
    "   - Deben ser claras, concisas y basadas únicamente en el fragmento.\n",
    "   - Deben responder directamente a la pregunta con un tono profesional y conversacional.\n",
    "4. **Tema**:\n",
    "   - Resume el tema principal del fragmento en el campo `topic` (máximo 50 caracteres).\n",
    "5. **Formato**:\n",
    "   - Retorna un objeto JSON que cumpla con el esquema de `Conversation`, con un campo `messages` que contenga una lista de objetos `Message` (con `role` = \"user\" o \"assistant\" y `content`) y un campo `topic`.\n",
    "\n",
    "<example>\n",
    "**Fragmento**:\n",
    "```\n",
    "(A)\n",
    "PERIODO DE TRANSICIÓN RELATIVO A LA IMPLEMENTACIÓN GENERAL DEL ACUERDO\n",
    "215.\n",
    "El Nuevo Acuerdo será aplicable a todos los bancos internacionalmente activos en cada nivel del grupo bancario. Aquellos países en los que la subconsolidación no es actualmente un requisito, tendrán un periodo de transición de tres años, a partir de la fecha de implementación, para aplicarla.\n",
    "(B)\n",
    "PERIODO DE TRANSICIÓN RELATIVO AL MÉTODO FUNDADO EN LA CALIFICACIÓN INTERNA\n",
    "216.\n",
    "El Comité reconoce que un respeto completo e inmediato de ciertos requisitos relacionados con datos podría no ser posible...\n",
    "```\n",
    "\n",
    "**Salida esperada**:\n",
    "```json\n",
    "{{\n",
    "    \"messages\": [\n",
    "        {{\"role\": \"user\", \"content\": \"¿Qué bancos deben cumplir con este acuerdo?\"}},\n",
    "        {{\"role\": \"assistant\", \"content\": \"Todos los bancos internacionalmente activos en cada nivel del grupo bancario.\"}},\n",
    "        {{\"role\": \"user\", \"content\": \"¿Por qué es necesaria la subconsolidación?\"}},\n",
    "        {{\"role\": \"assistant\", \"content\": \"Para garantizar que los riesgos se gestionen adecuadamente en todos los niveles del grupo bancario.\"}},\n",
    "        {{\"role\": \"user\", \"content\": \"¿Qué requisitos del método IRB se relajan durante el periodo de transición?\"}},\n",
    "        {{\"role\": \"assistant\", \"content\": \"Ciertos requisitos relacionados con datos para exposiciones empresariales, bancarias, soberanas y al detalle.\"}}\n",
    "    ],\n",
    "    \"topic\": \"Periodo de transición del Acuerdo de Basilea\"\n",
    "}}\n",
    "```\n",
    "\n",
    "<notes>\n",
    "- Evita repetir preguntas o respuestas similares para mantener la diversidad en múltiples iteraciones.\n",
    "- Asegúrate de que la conversación sea útil para entrenar modelos conversacionales, reflejando interacciones humanas verosímiles.\n",
    "- Si el fragmento es insuficiente para una conversación completa, genera un solo intercambio (1 pregunta y 1 respuesta).\n",
    "- no es necesario que la respuesta seamas de 2 intercambios, puede ser de un intercambio, siempre y cuando la respuesta del asistente sea lo mas detallada posible.\n",
    "- siempre cubre todo el contexto generando conversaciones, no te saltes ningun parrafo, usalo para la generacion de conversaciones.\n",
    "</notes>\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Llama a Ollama con roles system y user\n",
    "        response = await ollama_client.chat(\n",
    "            model=OLLAMA_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Eres un experto en el dominio del fragmento proporcionado (por ejemplo, regulaciones financieras, riesgos financieros, finanzas). Genera respuestas claras, concisas y basadas únicamente en el fragmento, manteniendo un tono profesional y conversacional, se especifico y detalla una respuestas en el intercambio de asistente.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            options={\n",
    "                \"temperature\": temperature,\n",
    "                \"top_p\": top_p,\n",
    "            },\n",
    "            format=Conversation.model_json_schema()  # Especifica el esquema JSON\n",
    "        )\n",
    "        conversation = Conversation.model_validate_json(response.message.content)\n",
    "        # Validar que la conversación tenga al menos un intercambio completo\n",
    "        if len(conversation.messages) < 2:\n",
    "            print(f\"Error: Conversación inválida, número de mensajes insuficiente: {len(conversation.messages)}\")\n",
    "            return None\n",
    "        # Si el número de mensajes es impar, eliminar el último (asumiendo que es del usuario)\n",
    "        if len(conversation.messages) % 2 != 0 and len(conversation.messages) > 2:\n",
    "            conversation.messages = conversation.messages[:-1]\n",
    "        return conversation\n",
    "    except Exception as e:\n",
    "        print(f\"Error generando conversación con Ollama: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f8506-c9ff-46cb-971c-4a01f32aac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "async def process_pdf(index, pdf_path, output_dir):\n",
    "    \"\"\"Procesa un PDF, genera conversaciones y las guarda en JSONL.\"\"\"\n",
    "    try:\n",
    "        \n",
    "        pages_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "        if not pages_text:\n",
    "            return\n",
    "    \n",
    "        jsonl_file = os.path.join(output_dir, f\"pdf_{index:04d}.jsonl\")\n",
    "        with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            tasks = [generate_conversation(fragment) for fragment in pages_text if len(fragment) > 20]\n",
    "    \n",
    "            conversations = await tqdm_asyncio.gather(*tasks,  desc=f\"Procesando Fragmentos para indice {index}...\")\n",
    "    \n",
    "            if conversations:\n",
    "                output = [messages.model_dump() for messages in conversations if messages is not None]\n",
    "                output_str = \"\\n\".join(json.dumps(messages, ensure_ascii=False) for messages in output)\n",
    "                f.write(output_str + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error el pdf {pdf_path}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fdbb014-2ca2-4f7f-bdfe-1430423e7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def process_pdf_wrapper(args):\n",
    "    index, pdf_path, output_dir = args\n",
    "    # Ejecutar la función asíncrona process_pdf dentro de un bucle de eventos\n",
    "    asyncio.run(process_pdf(index, pdf_path, output_dir))\n",
    "\n",
    "def generate():\n",
    "    pdf_files = files\n",
    "    output_dir=\"outputs\"\n",
    "    output_folder_path=Path(output_dir)\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    num_workers = int(min(multiprocessing.cpu_count() * 0.8,len(pdf_files)))\n",
    "    with ProcessPoolExecutor(max_workers=15) as executor:\n",
    "        list(tqdm(executor.map(process_pdf_wrapper, [(i, p, output_dir) for i, p in enumerate(pdf_files)]), total=len(pdf_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfe45b6-1566-44ee-bd25-001e9f76ea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 6...: 100%|██████████| 12/12 [03:12<00:00, 16.08s/it]it]\n",
      "Procesando Fragmentos para indice 16...:   0%|          | 0/56 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 5...: 100%|██████████| 12/12 [06:18<00:00, 31.51s/it]]  \n",
      "Procesando Fragmentos para indice 17...:   0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 7...: 100%|██████████| 18/18 [06:23<00:00, 21.32s/it]]\n",
      "Procesando Fragmentos para indice 18...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 9...: 100%|██████████| 11/11 [07:03<00:00, 38.53s/it]]\n",
      "Procesando Fragmentos para indice 19...:   0%|          | 0/92 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 13...: 100%|██████████| 22/22 [07:21<00:00, 20.07s/it]\n",
      "Procesando Fragmentos para indice 20...:   0%|          | 0/149 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 10...: 100%|██████████| 30/30 [17:03<00:00, 34.11s/it]  t]\n",
      "Procesando Fragmentos para indice 21...:   0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 2...: 100%|██████████| 50/50 [19:27<00:00, 23.36s/it]]it] \n",
      "Procesando Fragmentos para indice 22...:   0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 15...:  66%|██████▌   | 37/56 [20:46<05:56, 18.74s/it]t] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: 1 validation error for Conversation\n",
      "  Invalid JSON: EOF while parsing a value at line 1893 column 12 [type=json_invalid, input_value='{\\n  \"messages\": [\\n    ...o.\"}\\n  ,\\n    {\"role\":', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 8...: 100%|██████████| 2/2 [35:17<00:00, 1058.70s/it]]it] \n",
      "Procesando Fragmentos para indice 23...:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 3...: 100%|██████████| 55/55 [43:36<00:00, 47.58s/it]t]] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/2eeef27f-f8c8-43f4-8fd6-021d9bac29d1_SUPERBANCOS L1_XIII_cap_IV.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 24...:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 15...: 100%|██████████| 56/56 [44:24<00:00, 47.59s/it] ]\n",
      "Procesando Fragmentos para indice 25...:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 16...: 100%|██████████| 56/56 [1:10:42<00:00, 75.75s/it]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/a2deabd9-6a97-49ae-b9dd-eeb4a7c65079_manual_riesgos_mercado_liquidez_9_jul_10.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 26...:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 18...: 100%|██████████| 20/20 [1:15:28<00:00, 226.44s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/e0c61841-c704-48e0-a997-f8bf9ed3f5ed_manual_estructuras_datos_generalidades_1_abr_14.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 27...:   0%|          | 0/145 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 27...:   1%|          | 1/145 [00:00<00:17,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 19...: 100%|██████████| 92/92 [1:20:56<00:00, 52.79s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/94fbef1b-04a1-4266-b76a-8a0a5003305d_manual_control_inversiones_3_mar_17.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 28...:   0%|          | 0/90 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 11...: 100%|██████████| 101/101 [1:45:39<00:00, 62.77s/it]    \n",
      "Procesando Fragmentos para indice 29...:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 1...: 100%|██████████| 108/108 [1:45:49<00:00, 58.79s/it] \n",
      "Procesando Fragmentos para indice 30...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 30...: 100%|██████████| 1/1 [00:00<00:00, 179.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/3810aee5-6b5b-4348-abe6-30622e26db49_L1_XVIII_cap_IV.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 31...:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 21...: 100%|██████████| 53/53 [1:32:50<00:00, 105.10s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/135a6c7b-db28-4598-8047-5e3b7ea8ce3c_manual-para-la-gestion-de-riesgos-lavados-de-activos-y-financiacion-del-terrorismo.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 32...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 32...: 100%|██████████| 1/1 [00:00<00:00, 161.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/b004b496-c5d7-41a2-a4ae-e494b45ebfcb_L1_XVIII_cap_II.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 22...: 100%|██████████| 53/53 [1:34:21<00:00, 106.83s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/5a644c34-7570-42d0-9e18-454aca47bbec_manual-para-la-gestion-de-riesgos-lavados-de-activos-y-financiacion-del-terrorismo (1).pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 34...:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 34...: 100%|██████████| 2/2 [00:00<00:00, 100.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/67c1cdc1-2a46-4069-9017-db842a32bd23_L1_XI_cap_VI.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 23...: 100%|██████████| 5/5 [1:18:56<00:00, 947.31s/it]   it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/b07f4752-8788-4373-bbb4-96a4564444a4_L1_X_cap_III.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 36...:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 36...: 100%|██████████| 2/2 [00:00<00:00, 104.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/e5d954fe-eb63-4b83-adfa-4c04beae34de_L1_XI_cap_IV.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 24...: 100%|██████████| 10/10 [1:12:23<00:00, 434.36s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/7eabd3ed-7689-4bf8-8e63-bcd2d290bdba_L1_XVII_cap_V.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 38...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 38...: 100%|██████████| 1/1 [00:00<00:00, 78.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/6db9d821-4b1c-4c10-9967-1a8d46b04cab_L1_XI_cap_I.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 25...: 100%|██████████| 6/6 [1:12:11<00:00, 721.98s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/7d9e674e-2fd8-42ff-954f-f03505585198_L1_X_cap_II.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 40...:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 0...: 100%|██████████| 177/177 [2:02:29<00:00, 41.52s/it]    \n",
      "Procesando Fragmentos para indice 41...:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 26...: 100%|██████████| 5/5 [1:02:54<00:00, 754.88s/it] t]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/71137209-dfbd-436c-a853-7bbae46065ee_L1_XV_cap_I.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 42...:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 17...: 100%|██████████| 150/150 [2:13:56<00:00, 53.58s/it]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/6c353e73-74b0-4a61-9758-92073304c5a4_manual_operaciones_activas_contingentes_24_feb_17.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 43...:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 28...: 100%|██████████| 90/90 [1:06:32<00:00, 44.36s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/041f2417-eea1-4cd2-9352-ee98217c80b3_L1_XVII_cap_III.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 44...:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 20...: 100%|██████████| 149/149 [2:30:33<00:00, 60.62s/it]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/345b9ea9-77c8-42f3-bd03-6f67e2c6d4f0_manual-prevencion-lavado-activos-Ecuador.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 45...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 45...: 100%|██████████| 1/1 [00:00<00:00, 67.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/4a809773-d2b3-40cf-92be-d3fb403e8769_L1_XII_cap_III.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 46...:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 29...: 100%|██████████| 66/66 [56:57<00:00, 51.79s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/5daf6387-8855-4d65-8f1a-d83ac284afcf_L1_XVIII_cap_V.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 47...:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 31...: 100%|██████████| 12/12 [57:45<00:00, 288.79s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/c5fd1512-4d55-496f-9bcc-2c3bcd42fd88_L1_XVIII_cap_III.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 48...:   0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 33...: 100%|██████████| 6/6 [54:07<00:00, 541.28s/it]   \n",
      "Procesando Fragmentos para indice 49...:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 35...: 100%|██████████| 15/15 [51:20<00:00, 205.37s/it]   \n",
      "Procesando Fragmentos para indice 50...:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 37...: 100%|██████████| 3/3 [51:12<00:00, 1024.06s/it]  \n",
      "Procesando Fragmentos para indice 51...:   0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 51...:   2%|▏         | 1/47 [00:00<00:11,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 39...: 100%|██████████| 41/41 [52:22<00:00, 76.66s/it]    \n",
      "Procesando Fragmentos para indice 52...:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n",
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 40...: 100%|██████████| 6/6 [52:04<00:00, 520.82s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error el pdf /workspace/data/uploads/cee77942-694d-4fc3-8ba2-3ba799e29161_L1_XIX_cap_IV.pdf: 'NoneType' object has no attribute 'model_dump'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Fragmentos para indice 53...:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/97 [2:49:11<65:33:31, 2537.76s/it] ▏| 204/221 [2:49:04<1:10:12, 247.78s/it]\n",
      "Procesando Fragmentos para indice 56...:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Procesando Fragmentos para indice 61...:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 63...:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "Procesando Fragmentos para indice 57...:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 58...:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 62...:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Procesando Fragmentos para indice 66...:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 54...:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando Fragmentos para indice 55...:   0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 59...:   0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 65...:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Procesando Fragmentos para indice 67...:   0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 60...:   0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 64...:   0%|          | 0/1448 [00:00<?, ?it/s]\u001b[A\n",
      "Procesando Fragmentos para indice 68...:   0%|          | 0/28 [00:00<?, ?it/s]\u001b[AProcess ForkProcess-5:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-10:\n",
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-448' coro=<<async_generator_athrow without __name__>()>>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2942/1694343961.py\", line 16, in process_pdf\n",
      "    conversations = await tqdm_asyncio.gather(*tasks,  desc=f\"Procesando Fragmentos para indice {index}...\")\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2942/1694343961.py\", line 16, in process_pdf\n",
      "    conversations = await tqdm_asyncio.gather(*tasks,  desc=f\"Procesando Fragmentos para indice {index}...\")\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in gather\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in gather\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in <listcomp>\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "           ^^^^^^^\n",
      "  File \"/tmp/ipykernel_2942/1694343961.py\", line 16, in process_pdf\n",
      "    conversations = await tqdm_asyncio.gather(*tasks,  desc=f\"Procesando Fragmentos para indice {index}...\")\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in <listcomp>\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "           ^^^^^^^\n",
      "  File \"/tmp/ipykernel_2942/1694343961.py\", line 16, in process_pdf\n",
      "    conversations = await tqdm_asyncio.gather(*tasks,  desc=f\"Procesando Fragmentos para indice {index}...\")\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py\", line 611, in _wait_for_one\n",
      "    f = await done.get()\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py\", line 611, in _wait_for_one\n",
      "    f = await done.get()\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in gather\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/queues.py\", line 158, in get\n",
      "    await getter\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/queues.py\", line 158, in get\n",
      "    await getter\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in gather\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in <listcomp>\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "           ^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "asyncio.exceptions.CancelledError\n",
      "  File \"/workspace/venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 79, in <listcomp>\n",
      "    res = [await f for f in cls.as_completed(ifs, loop=loop, timeout=timeout,\n",
      "           ^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py\", line 611, in _wait_for_one\n",
      "    f = await done.get()\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/tasks.py\", line 611, in _wait_for_one\n",
      "    f = await done.get()\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 261, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/queues.py\", line 158, in get\n",
      "    await getter\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 261, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/queues.py\", line 158, in get\n",
      "    await getter\n",
      "asyncio.exceptions.CancelledError\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in _process_chunk\n",
      "    return [fn(*args) for args in chunk]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in _process_chunk\n",
      "    return [fn(*args) for args in chunk]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in <listcomp>\n",
      "    return [fn(*args) for args in chunk]\n",
      "            ^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in <listcomp>\n",
      "    return [fn(*args) for args in chunk]\n",
      "            ^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2942/3565369420.py\", line 11, in process_pdf_wrapper\n",
      "    asyncio.run(process_pdf(index, pdf_path, output_dir))\n",
      "  File \"/tmp/ipykernel_2942/3565369420.py\", line 11, in process_pdf_wrapper\n",
      "    asyncio.run(process_pdf(index, pdf_path, output_dir))\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 261, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 261, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in _process_chunk\n",
      "    return [fn(*args) for args in chunk]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in _process_chunk\n",
      "    return [fn(*args) for args in chunk]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in <listcomp>\n",
      "    return [fn(*args) for args in chunk]\n",
      "            ^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 210, in <listcomp>\n",
      "    return [fn(*args) for args in chunk]\n",
      "            ^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/tmp/ipykernel_2942/3565369420.py\", line 11, in process_pdf_wrapper\n",
      "    asyncio.run(process_pdf(index, pdf_path, output_dir))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/tmp/ipykernel_2942/3565369420.py\", line 11, in process_pdf_wrapper\n",
      "    asyncio.run(process_pdf(index, pdf_path, output_dir))\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 263, in _process_worker\n",
      "    exc = _ExceptionWithTraceback(e, e.__traceback__)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 263, in _process_worker\n",
      "    exc = _ExceptionWithTraceback(e, e.__traceback__)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 131, in __init__\n",
      "    tb = ''.join(format_exception(type(exc), exc, tb))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 131, in __init__\n",
      "    tb = ''.join(format_exception(type(exc), exc, tb))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 139, in format_exception\n",
      "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 139, in format_exception\n",
      "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 787, in __init__\n",
      "    context = TracebackException(\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 728, in __init__\n",
      "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 263, in _process_worker\n",
      "    exc = _ExceptionWithTraceback(e, e.__traceback__)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 728, in __init__\n",
      "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 425, in _extract_from_extended_frame_gen\n",
      "    result.append(FrameSummary(\n",
      "                  ^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 263, in _process_worker\n",
      "    exc = _ExceptionWithTraceback(e, e.__traceback__)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 131, in __init__\n",
      "    tb = ''.join(format_exception(type(exc), exc, tb))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 429, in _extract_from_extended_frame_gen\n",
      "    linecache.checkcache(filename)\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 261, in __init__\n",
      "    def __init__(self, filename, lineno, name, *, lookup_line=True,\n",
      "    \n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/concurrent/futures/process.py\", line 131, in __init__\n",
      "    tb = ''.join(format_exception(type(exc), exc, tb))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 139, in format_exception\n",
      "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/linecache.py\", line 72, in checkcache\n",
      "    stat = os.stat(fullname)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 139, in format_exception\n",
      "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 787, in __init__\n",
      "    context = TracebackException(\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 728, in __init__\n",
      "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 728, in __init__\n",
      "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 413, in _extract_from_extended_frame_gen\n",
      "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 413, in _extract_from_extended_frame_gen\n",
      "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 350, in _walk_tb_with_full_positions\n",
      "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 350, in _walk_tb_with_full_positions\n",
      "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 364, in _get_code_position\n",
      "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11-linux-x86_64-gnu/lib/python3.11/traceback.py\", line 364, in _get_code_position\n",
      "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.27 s, sys: 1.68 s, total: 4.95 s\n",
      "Wall time: 2h 49min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a4ebf-86b7-4ce0-a89a-975ee4a86092",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1685376-51e6-4287-a74e-26a1e3deffb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4bf20d9d5d429a87a1522c0622cab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cc3b1f5a8d41188412819e28b55e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/96 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b78dc506ac400fbfcf72115ca01365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages', 'topic'],\n",
       "        num_rows: 664\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"./outputs/*.jsonl\")\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa783a63-83da-4cd0-97a3-dc50d15df2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0302c5a93ee748c19fce35827aaa637e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "151e67bb-0111-4991-b87d-e724b183ea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f927e39d7bc4dfc9d55557c21ac7edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2593e683346a4d229b5e9c6d5c0481b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdb167115d14860a59947184dcab9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0569c44f34e6422d9c78ce1f9e5eeba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1d7e93c0804ab8aab28fb1266739cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########|  270kB /  270kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2027803f4d423bb6cb7c5ceb339b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jeanmcm/b_risks/commit/13e6a6ad8f5d4eb1efc3bf36fe4e0b58c6e237fb', commit_message='Upload dataset', commit_description='', oid='13e6a6ad8f5d4eb1efc3bf36fe4e0b58c6e237fb', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jeanmcm/b_risks', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jeanmcm/b_risks'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"jeanmcm/b_risks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f0891",
   "metadata": {},
   "source": [
    "# Testing RAG with Open WebUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01ce0bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Respuesta en streaming:</b> El riesgo financiero se refiere a las posibles pérdidas o daños económicos que pueden afectar a una empresa, individuo u organización debido a sus actividades financieras. Esto puede incluir la incertidumbre sobre los rendimientos de los activos financieros, el valor de los bienes y servicios, o la capacidad de un individuo o organización para generar ingresos.\n",
       "\n",
       "En el contexto del sistema financiero, las instituciones deben conocer a fondo las características particulares de las actividades económicas de sus clientes y las operaciones que realizan para identificar y gestionar los riesgos financieros asociados. Esto es fundamental para prevenir la ocurrencia de incumplimientos en las regulaciones financieras y minimizar el impacto de cualquier pérdida o daño.\n",
       "\n",
       "Según el artículo 43 del \"Bsoft Documents\", las instituciones del sistema financiero deben contar con una unidad de cumplimiento dirigida por un oficial de cumplimiento, que debe tener formación profesional en áreas como administración, contaduría, derecho o economía. Este equipo es responsable de garantizar que las políticas y procedimientos financieros sean adecuados y cumplan con los requisitos legales.\n",
       "\n",
       "Por lo tanto, el riesgo financiero se considera un aspecto crítico para las instituciones del sistema financiero, ya que puede tener graves consecuencias en su estabilidad y solvencia. Es importante que estas entidades tomen medidas proactivas para identificar, evaluar y gestionar los riesgos financieros asociados con sus actividades y operaciones.\n",
       "\n",
       "No se incluye ninguna cita porque no hay un id atributo en el source tag correspondiente a esta información, pero la respuesta se basa en el contexto proporcionado.."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "url = \"https://vwlppjjfa98c9x-8080.proxy.runpod.net\"\n",
    "api_key =\"sk-05568562f28844fe997cadf960a346cd\"\n",
    "\n",
    "messages =  [{\"role\": \"user\", \"content\": \"Que es el Riesgo Financiero?\"}]\n",
    "\n",
    "try:\n",
    "    # Realizar la solicitud con stream=True\n",
    "    with requests.post(f\"{url}/api/chat/completions\", stream=True,headers={\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    },json={\n",
    "      \"model\":\"bosft-riesgos-rag-model\",\n",
    "      \"messages\":messages,\n",
    "      \"stream\":True\n",
    "      }) as response:\n",
    "        response.raise_for_status()\n",
    "        # Variable para almacenar la salida acumulada\n",
    "        accumulated_output = \"\"\n",
    "\n",
    "        # Iterar sobre las líneas de la respuesta\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                # Decodificar la línea\n",
    "                decoded_line = line.decode('utf-8').strip()\n",
    "                # Si la línea comienza con \"data:\", extraer el contenido\n",
    "                if decoded_line.startswith(\"data:\"):\n",
    "                    decoded_line = decoded_line[5:].strip()  # Quitar \"data: \"\n",
    "\n",
    "                # Ignorar líneas vacías o marcadores de fin como \"[DONE]\"\n",
    "                if not decoded_line or decoded_line == \"[DONE]\" :\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    # Parsear si es JSON\n",
    "                    data = json.loads(decoded_line)\n",
    "                    if \"choices\" not in data: continue\n",
    "                    \n",
    "                    delta = data['choices'][0]['delta']\n",
    "                    if \"content\" in delta: new_data = delta['content']\n",
    "                except json.JSONDecodeError:\n",
    "                    # Si no es JSON, usar la línea como texto\n",
    "                    new_data = decoded_line\n",
    "\n",
    "                # Acumular y mostrar la salida dinámicamente\n",
    "                if new_data:\n",
    "                    accumulated_output += new_data\n",
    "                    # Limpiar la salida anterior y mostrar la nueva\n",
    "                    clear_output(wait=True)\n",
    "                    display(HTML(f\"<b>Respuesta en streaming:</b> {accumulated_output}\"))\n",
    "                    time.sleep(0.1)  # Pequeña pausa para visibilidad\n",
    "                    \n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\\nError en la solicitud: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64806a-ac56-417a-8dd9-175c3a8447a1",
   "metadata": {},
   "source": [
    "# Testing with Flowise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cb1c0-bb15-4c97-9e0c-0156e8b90df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
