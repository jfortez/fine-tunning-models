{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067529bb",
   "metadata": {},
   "source": [
    "# Generacion de Datasets utilizando RLHF para fine tunning\n",
    "\n",
    "## Procedimiento\n",
    "\n",
    "- Recoleccion de Datos: Obtener Informacion mediante documentos de textos seleccionables (no escaneados), mediante web, redes sociales, scrapping,etc\n",
    "- Extraer Texto: Usa PyMuPDF para extraer texto de PDFs no escaneados, procesando en paralelo con ProcessPoolExecutor para manejar grandes volúmenes (>100, >10,000).\n",
    "- Limpiar Datos: Elimina espacios múltiples y caracteres no deseados con expresiones regulares, asegurando texto coherente.\n",
    "- Validar: Verifica que los fragmentos extraídos no estén vacíos y tengan una longitud mínima (por ejemplo, 50 caracteres).\n",
    "- Generar Conversaciones: Divide el texto en párrafos, usa un modelo como meta-llama/Llama-3.2-1B-Instruct para generar diálogos conversacionales específicos al contenido, con al menos 4 intercambios por conversación, en formato {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}], \"topic\": \"...\"}.\n",
    "- Estructurar Dataset: Guarda las conversaciones en archivos JSONL con dos columnas: \"messages\" y \"topic\".\n",
    "Cargar y Subir: Carga el dataset con load_dataset(\"json\", data_files=\"path/*.jsonl\") y súbelo a un repositorio privado en Hugging Face Hub con push_to_hub(\"username/dataset_name\", private=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45295ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.5.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx>=0.27 (from ollama)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch)\n",
      "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.venv/lib/python3.11/site-packages (from triton==3.4.0->torch) (65.5.0)\n",
      "Collecting anyio (from httpx>=0.27->ollama)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting certifi (from httpx>=0.27->ollama)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27->ollama)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.27->ollama)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27->ollama)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9->ollama)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27->ollama)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ollama-0.5.2-py3-none-any.whl (13 kB)\n",
      "Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m240.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m197.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m223.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m152.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m187.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m150.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m243.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m144.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m156.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.2/107.2 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-inspection, triton, tqdm, sympy, sniffio, regex, pymupdf, pydantic-core, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, joblib, idna, h11, fsspec, filelock, click, certifi, annotated-types, pydantic, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, jinja2, httpcore, anyio, nvidia-cusolver-cu12, httpx, torch, ollama\n",
      "Successfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 anyio-4.10.0 certifi-2025.8.3 click-8.2.1 filelock-3.18.0 fsspec-2025.7.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jinja2-3.1.6 joblib-1.5.1 mpmath-1.3.0 networkx-3.5 nltk-3.9.1 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 ollama-0.5.2 pydantic-2.11.7 pydantic-core-2.33.2 pymupdf-1.26.3 regex-2025.7.34 sniffio-1.3.1 sympy-1.14.0 torch-2.8.0 tqdm-4.67.1 triton-3.4.0 typing-inspection-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pymupdf nltk ollama torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa351d6-c527-423f-9d2e-417d0ef2b8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4760f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "TEMPERATURE = 0.7  # Equilibrio entre creatividad y coherencia\n",
    "TOP_P = 0.9  # Filtrado de núcleo para diversidad\n",
    "MIN_CONVERSATION_LENGTH = 3 \n",
    "\n",
    "# Constantes\n",
    "MIN_FRAGMENT_LENGTH = 500\n",
    "MAX_FRAGMENT_LENGTH = 2000\n",
    "REPEAT_THRESHOLD = 0.3\n",
    "MIN_BLOCK_LENGTH = 30  # Reducido de 50 a 30 para incluir bloques más cortos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be033f",
   "metadata": {},
   "source": [
    "### Recoleccion de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b45b0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Folder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Verificar si la carpeta existe\n",
    "\n",
    "folder_url = \"./docs\"\n",
    "folder = Path(folder_url)\n",
    "\n",
    "\n",
    "if folder.exists() and folder.is_dir():\n",
    "    print(\"Valid Folder\")\n",
    "    \n",
    "# Obtener todos los archivos de la carpeta\n",
    "files = [f for f in folder.rglob(\"*\") if f.is_file()]\n",
    "\n",
    "files\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4f060",
   "metadata": {},
   "source": [
    "### Extraccion de Texto y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed080bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "import os\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text, repeated_blocks=None):\n",
    "    \"\"\"Limpia el texto, eliminando caracteres repetitivos, texto redundante y caracteres no deseados.\"\"\"\n",
    "    # Eliminar caracteres de control no deseados (excepto \\n)\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', text)\n",
    "    # Eliminar patrones repetitivos como ----, ...., ****\n",
    "    text = re.sub(r'([^\\w\\s])\\1{2,}|\\s*[.]{3,}\\s*', '', text)\n",
    "    # Normalizar espacios múltiples\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    # Eliminar espacios al inicio y final de cada línea\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    # Filtrar líneas duplicadas, números, correos y contenido administrativo\n",
    "    seen_lines = set()\n",
    "    unique_lines = []\n",
    "    for line in lines:\n",
    "        if line not in seen_lines and \\\n",
    "           not re.match(r'^\\d+$', line) and \\\n",
    "           not re.match(r'.*@(.*\\.)+.*', line) and \\\n",
    "           not re.match(r'^(Tel|Fax|E-mail|www\\.).*', line, re.IGNORECASE) and \\\n",
    "           (repeated_blocks is None or line not in repeated_blocks):\n",
    "            unique_lines.append(line)\n",
    "            seen_lines.add(line)\n",
    "    return '\\n'.join(unique_lines)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extrae texto de un PDF en una sola pasada, preservando el texto del inicio de la página,\n",
    "    eliminando encabezados, pies de página y contenido irrelevante,\n",
    "    dividiendo en fragmentos de 500 a 2000 caracteres con metadata corregida.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path)\n",
    "        total_pages = len(doc)\n",
    "        chunks = []\n",
    "        current_chunk = []  # Lista de (párrafo, página)\n",
    "        current_chunk_length = 0\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        block_counter = Counter()\n",
    "\n",
    "        for page_number in range(1, total_pages + 1):\n",
    "            page = doc[page_number - 1]\n",
    "            page_height = page.rect.height\n",
    "            blocks = page.get_text(\"blocks\")\n",
    "            page_text = []\n",
    "\n",
    "            # Procesar bloques y filtrar encabezados/pies de página\n",
    "            for block in blocks:\n",
    "                text = block[4]\n",
    "                y0, y1 = block[1], block[3]\n",
    "                # Excluir pies de página (parte inferior de la página)\n",
    "                if y1 > 0.95 * page_height:  # Relajado de 0.95 a 0.9\n",
    "                    continue\n",
    "                # Excluir encabezados solo si son repetitivos\n",
    "                if y0 < 0.05 * page_height:  # Relajado de 0.05 a 0.1\n",
    "                    block_counter[text] += 1\n",
    "                    if block_counter[text] > total_pages * REPEAT_THRESHOLD:\n",
    "                        continue\n",
    "                if text and len(text) >= MIN_BLOCK_LENGTH:\n",
    "                    block_counter[text] += 1\n",
    "                    page_text.append((text, page_number))\n",
    "\n",
    "            # Si no hay texto válido en la página, continuar\n",
    "            if not page_text:\n",
    "                continue\n",
    "\n",
    "            # Acumular párrafos con su número de página\n",
    "            for paragraph, page in page_text:\n",
    "                current_chunk.append((paragraph, page))\n",
    "                current_chunk_length += len(paragraph) + 2  # +2 por \"\\n\\n\"\n",
    "\n",
    "                # Si el fragmento alcanza la longitud mínima, procesarlo\n",
    "                if current_chunk_length >= MIN_FRAGMENT_LENGTH:\n",
    "                    chunk_text = \"\\n\\n\".join(p for p, _ in current_chunk)\n",
    "                    cleaned_chunk = clean_text(chunk_text, None)\n",
    "                    cleaned_length = len(cleaned_chunk)\n",
    "\n",
    "                    # Obtener el rango de páginas del fragmento\n",
    "                    page_numbers = sorted(set(page for _, page in current_chunk))\n",
    "                    start_page = page_numbers[0] if page_numbers else page_number\n",
    "                    end_page = page_numbers[-1] if page_numbers else page_number\n",
    "\n",
    "                    # Dividir fragmentos largos\n",
    "                    while cleaned_length > MAX_FRAGMENT_LENGTH:\n",
    "                        sub_chunk = cleaned_chunk[:MAX_FRAGMENT_LENGTH]\n",
    "                        last_paragraph_end = sub_chunk.rfind(\"\\n\\n\")\n",
    "                        if last_paragraph_end == -1:\n",
    "                            last_paragraph_end = MAX_FRAGMENT_LENGTH\n",
    "                        chunk_to_add = cleaned_chunk[:last_paragraph_end].strip()\n",
    "\n",
    "                        # Calcular el número de páginas para el subfragmento\n",
    "                        chars_so_far = 0\n",
    "                        sub_chunk_pages = []\n",
    "                        for paragraph, page in current_chunk:\n",
    "                            chars_so_far += len(paragraph) + 2\n",
    "                            if chars_so_far <= last_paragraph_end:\n",
    "                                sub_chunk_pages.append(page)\n",
    "                            else:\n",
    "                                break\n",
    "                        sub_start_page = min(sub_chunk_pages) if sub_chunk_pages else page_number\n",
    "                        sub_end_page = max(sub_chunk_pages) if sub_chunk_pages else page_number\n",
    "\n",
    "                        metadata = (\n",
    "                            f\"# FILENAME: {filename} | CHARACTERS: {len(chunk_to_add)} | \"\n",
    "                            f\"PAGES: {sub_start_page}-{sub_end_page}/{total_pages}\\n\\n\"\n",
    "                        )\n",
    "                        chunks.append((metadata + chunk_to_add, hashlib.md5(chunk_to_add.encode()).hexdigest()))\n",
    "                        cleaned_chunk = cleaned_chunk[last_paragraph_end:].strip()\n",
    "                        cleaned_length = len(cleaned_chunk)\n",
    "\n",
    "                        # Actualizar current_chunk para los párrafos restantes\n",
    "                        remaining_chunk = []\n",
    "                        chars_so_far = 0\n",
    "                        for paragraph, page in current_chunk:\n",
    "                            chars_so_far += len(paragraph) + 2\n",
    "                            if chars_so_far > last_paragraph_end:\n",
    "                                remaining_chunk.append((paragraph, page))\n",
    "                        current_chunk = remaining_chunk\n",
    "                        current_chunk_length = cleaned_length\n",
    "                        page_numbers = sorted(set(page for _, page in current_chunk))\n",
    "                        start_page = page_numbers[0] if page_numbers else page_number\n",
    "\n",
    "                    # Añadir el fragmento completo\n",
    "                    if cleaned_length >= MIN_FRAGMENT_LENGTH:\n",
    "                        metadata = (\n",
    "                            f\"# FILENAME: {filename} | CHARACTERS: {cleaned_length} | \"\n",
    "                            f\"PAGES: {start_page}-{end_page}/{total_pages}\\n\\n\"\n",
    "                        )\n",
    "                        chunks.append((metadata + cleaned_chunk, hashlib.md5(cleaned_chunk.encode()).hexdigest()))\n",
    "                        current_chunk = []\n",
    "                        current_chunk_length = 0\n",
    "\n",
    "                    else:\n",
    "                        current_chunk = [(cleaned_chunk, page_numbers[-1])] if page_numbers else []\n",
    "                        current_chunk_length = cleaned_length\n",
    "\n",
    "        # Añadir el fragmento final si cumple con la longitud mínima\n",
    "        if current_chunk and current_chunk_length >= MIN_FRAGMENT_LENGTH:\n",
    "            chunk_text = \"\\n\\n\".join(p for p, _ in current_chunk)\n",
    "            cleaned_chunk = clean_text(chunk_text, None)\n",
    "            cleaned_length = len(cleaned_chunk)\n",
    "            if cleaned_length >= MIN_FRAGMENT_LENGTH:\n",
    "                page_numbers = sorted(set(page for _, page in current_chunk))\n",
    "                start_page = page_numbers[0] if page_numbers else total_pages\n",
    "                end_page = page_numbers[-1] if page_numbers else total_pages\n",
    "                metadata = (\n",
    "                    f\"# FILENAME: {filename} | CHARACTERS: {cleaned_length} | \"\n",
    "                    f\"PAGES: {start_page}-{end_page}/{total_pages}\\n\\n\"\n",
    "                )\n",
    "                chunks.append((metadata + cleaned_chunk, hashlib.md5(cleaned_chunk.encode()).hexdigest()))\n",
    "\n",
    "        doc.close()\n",
    "\n",
    "        # Filtrar bloques repetitivos y duplicados\n",
    "        repeated_blocks = {text for text, count in block_counter.items() if count > total_pages * REPEAT_THRESHOLD}\n",
    "        final_chunks = []\n",
    "        seen_hashes = set()\n",
    "\n",
    "        for chunk, chunk_hash in chunks:\n",
    "            chunk_text = '\\n'.join(line for line in chunk.splitlines() if not line.startswith('#'))\n",
    "            cleaned_chunk = clean_text(chunk_text, repeated_blocks)\n",
    "            if len(cleaned_chunk) >= MIN_FRAGMENT_LENGTH and chunk_hash not in seen_hashes:\n",
    "                # Actualizar la longitud en la metadata después de la limpieza final\n",
    "                metadata_lines = chunk.splitlines()[0]\n",
    "                metadata = re.sub(r'CHARACTERS: \\d+', f'CHARACTERS: {len(cleaned_chunk)}', metadata_lines)\n",
    "                final_chunks.append(f\"{metadata}\\n\\n{cleaned_chunk}\")\n",
    "                seen_hashes.add(chunk_hash)\n",
    "\n",
    "        return final_chunks if final_chunks else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {pdf_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912cd27",
   "metadata": {},
   "source": [
    "### Generar Conversaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2c9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import AsyncClient\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Definir el esquema Pydantic para la salida estructurada\n",
    "class Message(BaseModel):\n",
    "    role: str = Field(..., pattern=\"^(system|user|assistant)$\")\n",
    "    content: str\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    messages: List[Message] = Field(..., min_items=MIN_CONVERSATION_LENGTH)\n",
    "    topic: str\n",
    "\n",
    "ollama_client = AsyncClient()\n",
    "\n",
    "def get_prompt(fragment:str):\n",
    "  return f\"\"\"\n",
    "Basado en el siguiente contexto:\n",
    "<context>\n",
    "{fragment}\n",
    "</context>\n",
    "\n",
    "<instructions>\n",
    "Genera una conversación entre un usuario y un asistente basada **exclusivamente** en el contenido de <context>...</context>. La conversación debe seguir este formato y estilo:\n",
    "\n",
    "1. **Formato de salida**:\n",
    "   - Devuelve un objeto JSON con dos campos:\n",
    "     - \"messages\": lista de objetos con la forma {{ \"role\": \"user\" | \"assistant\", \"content\": \"string\" }}\n",
    "     - \"topic\": cadena corta (máximo 50 caracteres) que resume el tema del fragmento.\n",
    "\n",
    "2. **Estructura de la conversación**:\n",
    "   - Longitud: entre **1 y 2 intercambios** (2 a 4 mensajes).\n",
    "   - Usa UNA de estas dos opciones:\n",
    "     - **Opción A**: 1 intercambio (2 mensajes). Ambos deben ser **largos y detallados**.\n",
    "     - **Opción B**: 2 intercambios (4 mensajes). Cada respuesta debe ser extensa y cubrir bien el contenido.\n",
    "   - cada intercambio (par de mensajes) debe cumplir lo siguiente: empieza con el role: \"user\" y termina con el role: \"assistant\", en otras palabras, formato conversacional cumpliento el formato SFT (Supervices Fine Tunning)\n",
    "\n",
    "3. **Intervenciones del usuario**:\n",
    "   - **No incluyas frases como**:\n",
    "     - “según el texto”, “en el fragmento”, “respecto al documento”, “basado en este artículo”, etc.\n",
    "   - Deben ser naturales, humanas y relevantes.\n",
    "   - Pueden adoptar estas formas:\n",
    "     - Preguntas específicas o inferenciales.\n",
    "     - Frases incompletas para completar.\n",
    "     - Comentarios o afirmaciones parcialmente desarrolladas.\n",
    "   - Las intervenciones deben seguir un flujo lógico y coherente.\n",
    "\n",
    "4. **Respuestas del asistente**:\n",
    "   - Claras, profesionales y bien estructuradas.\n",
    "   - Basadas **únicamente en el contenido del contexto**.\n",
    "   - Extensas, ricas en detalles y sin añadir información inventada.\n",
    "   - Usa un tono conversacional técnico o divulgativo según el tema.\n",
    "\n",
    "5. **Cobertura y contenido**:\n",
    "   - Cubre **todo el contenido** del fragmento.\n",
    "   - No ignores secciones importantes ni temas mencionados.\n",
    "   - Si el texto es poco claro, genera igualmente un solo intercambio lo más plausible posible.\n",
    "\n",
    "6. **Objetivo de esta conversación**:\n",
    "   - Este formato será usado para entrenar modelos mediante *Supervised Fine-Tuning (SFT)* usando `SFTTrainer` de Hugging Face.\n",
    "   - Busca generar conversaciones verosímiles y útiles para entrenar modelos en comprensión lectora, generación coherente y natural.\n",
    "\n",
    "<example>\n",
    "**Fragmento técnico**:\n",
    "PERIODO DE TRANSICIÓN RELATIVO A LA IMPLEMENTACIÓN GENERAL DEL ACUERDO  \n",
    "215. El Nuevo Acuerdo será aplicable a todos los bancos internacionalmente activos en cada nivel del grupo bancario. Aquellos países en los que la subconsolidación no es actualmente un requisito, tendrán un periodo de transición de tres años, a partir de la fecha de implementación, para aplicarla.  \n",
    "\n",
    "PERIODO DE TRANSICIÓN RELATIVO AL MÉTODO FUNDADO EN LA CALIFICACIÓN INTERNA  \n",
    "216. El Comité reconoce que un respeto completo e inmediato de ciertos requisitos relacionados con datos podría no ser posible, particularmente para exposiciones frente a empresas, bancos, soberanos y retail. Para estos casos, se prevé un periodo de transición limitado durante el cual las entidades podrán utilizar aproximaciones alternativas.\n",
    "\n",
    "**Salida esperada**:\n",
    "```json\n",
    "{{\n",
    "  \"messages\": [\n",
    "    {{\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"¿Qué ocurre en los países donde la subconsolidación no es obligatoria y cómo afecta esto a la aplicación del acuerdo?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"En esos países, se establece un periodo de transición de tres años a partir de la implementación del acuerdo. Esto les permite adaptarse gradualmente a los nuevos requisitos regulatorios sin enfrentar impactos abruptos. La subconsolidación es esencial para asegurar una visión completa del riesgo dentro de los grupos bancarios, y este periodo transitorio facilita su adopción progresiva.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"¿Qué flexibilidades se contemplan para las entidades financieras en relación con los datos requeridos por el método basado en calificación interna?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"El texto reconoce que ciertos requisitos de datos pueden ser difíciles de cumplir de inmediato, especialmente en exposiciones a empresas, bancos, gobiernos y clientes minoristas. Por ello, se permite un periodo de transición limitado durante el cual las instituciones pueden aplicar aproximaciones alternativas. Esto proporciona margen para ajustar los sistemas internos y recopilar datos adecuados sin comprometer la supervisión del riesgo.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"role\": \"user\",\n",
    "      \"content\":\"acuerdo 215\"\n",
    "    }},\n",
    "    {{\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\":\"El Nuevo Acuerdo se aplicará a todos los bancos con actividad internacional en cada nivel de su grupo bancario. Los países donde la subconsolidación no sea actualmente obligatoria dispondrán de un período de transición de tres años, a partir de la fecha de implementación, para adoptarla.\"\n",
    "    }}\n",
    "  ],\n",
    "  \"topic\": \"Transición en la implementación del acuerdo\"\n",
    "}}\n",
    "```\n",
    "\n",
    "**Fragmento simple**:\n",
    "El cielo es azul porque las moléculas en la atmósfera dispersan la luz azul del sol en todas direcciones. Esta dispersión se llama dispersión de Rayleigh.\n",
    "\n",
    "**Salida esperada**:\n",
    "```json\n",
    "{{\n",
    "  \"messages\": [\n",
    "    {{\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"¿Por qué el cielo tiene ese color azul tan característico durante el día?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"El color azul del cielo se debe a un fenómeno llamado dispersión de Rayleigh. Cuando la luz del sol entra en la atmósfera terrestre, interactúa con las moléculas de aire. La luz azul, que tiene una longitud de onda más corta, se dispersa mucho más fácilmente que otros colores. Esta dispersión hace que el azul se difunda en todas direcciones, lo cual es lo que vemos desde cualquier punto del planeta durante el día. Por eso el cielo parece predominantemente azul cuando el sol está alto.\"\n",
    "    }}\n",
    "  ],\n",
    "  \"topic\": \"Dispersión de la luz en la atmósfera\"\n",
    "}}\n",
    "```\n",
    "</example>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "async def generate_conversation(fragment, temperature=TEMPERATURE, top_p=TOP_P):\n",
    "    \"\"\"\n",
    "    Genera una conversación estructurada en formato JSON usando Ollama, basada en un fragmento de texto.\n",
    "    Optimizado para múltiples iteraciones en la generación de datasets para fine-tuning.\n",
    "    \"\"\"\n",
    "    if not fragment or len(fragment) < MIN_FRAGMENT_LENGTH:\n",
    "        print(f\"Error: Fragmento demasiado corto ({len(fragment)} caracteres).\")\n",
    "        return None\n",
    "\n",
    "    # Extraer el texto sin la metadata (líneas que comienzan con '#')\n",
    "    fragment_content = '\\n'.join(line for line in fragment.splitlines() if not line.startswith('#')).strip()\n",
    "    if len(fragment_content) < MIN_FRAGMENT_LENGTH:\n",
    "        print(f\"Error: Contenido útil del fragmento demasiado corto ({len(fragment_content)} caracteres).\")\n",
    "        return None\n",
    "\n",
    "    # Prompt optimizado para múltiples iteraciones\n",
    "    prompt = get_prompt(fragment_content)\n",
    "\n",
    "    try:\n",
    "        # Llama a Ollama con roles system y user\n",
    "        response = await ollama_client.chat(\n",
    "            model=OLLAMA_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Eres un experto en el dominio del fragmento proporcionado (por ejemplo, regulaciones financieras, riesgos financieros, finanzas). Genera respuestas claras, concisas y basadas únicamente en el fragmento, manteniendo un tono profesional y conversacional, se especifico y detalla una respuestas en el intercambio de asistente.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            options={\n",
    "                \"temperature\": temperature,\n",
    "                \"top_p\": top_p,\n",
    "                #\"num_ctx\":\n",
    "                \n",
    "                \n",
    "            },\n",
    "            format=Conversation.model_json_schema()  # Especifica el esquema JSON\n",
    "            \n",
    "        )\n",
    "        conversation = Conversation.model_validate_json(response.message.content)\n",
    "        # Validar que la conversación tenga al menos un intercambio completo\n",
    "        if len(conversation.messages) < 2:\n",
    "            print(f\"Error: Conversación inválida, número de mensajes insuficiente: {len(conversation.messages)}\")\n",
    "            return None\n",
    "        # Si el número de mensajes es impar, eliminar el último (asumiendo que es del usuario)\n",
    "        if len(conversation.messages) % 2 != 0 and len(conversation.messages) > 2:\n",
    "            conversation.messages = conversation.messages[:-1]\n",
    "        return conversation\n",
    "    except Exception as e:\n",
    "        print(f\"Error generando conversación con Ollama: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43e9efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "class MetadataManager:\n",
    "    \"\"\"Clase para manejar archivos de metadatos JSON.\"\"\"\n",
    "    def __init__(self, index: int, output_dir: str):\n",
    "        self.folder = os.path.join(output_dir, \"metadata\")\n",
    "        self.metadata_file = os.path.join(self.folder, f\"metadata_{index:04d}.json\")\n",
    "        os.makedirs(self.folder, exist_ok=True)\n",
    "\n",
    "    def exists(self) -> bool:\n",
    "        \"\"\"Verifica si el archivo de metadatos existe.\"\"\"\n",
    "        return os.path.exists(self.metadata_file)\n",
    "\n",
    "    def get(self, param: str):\n",
    "        \"\"\"Obtiene chunks, conversations o fileName desde el archivo de metadatos.\"\"\"\n",
    "        if not self.exists():\n",
    "            return [] if param in [\"chunks\", \"conversations\"] else \"\"\n",
    "        try:\n",
    "            with open(self.metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                metadata = json.load(f)\n",
    "                return metadata.get(param, []) if param in [\"chunks\", \"conversations\"] else metadata.get(param, \"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer {param} desde {self.metadata_file}: {e}\")\n",
    "            return [] if param in [\"chunks\", \"conversations\"] else \"\"\n",
    "\n",
    "    def set(self, param: str, value):\n",
    "        \"\"\"Establece chunks, conversations o fileName en el archivo de metadatos.\"\"\"\n",
    "        try:\n",
    "            metadata = {\"chunks\": [], \"fileName\": \"\", \"conversations\": []}\n",
    "            if self.exists():\n",
    "                with open(self.metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    metadata = json.load(f)\n",
    "            \n",
    "            metadata[param] = value\n",
    "            with open(self.metadata_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al escribir {param} en {self.metadata_file}: {e}\")\n",
    "\n",
    "def get_text_from_pdf(index: int, pdf_path: str, output_dir: str) -> list:\n",
    "    \"\"\"Obtiene el texto de un PDF desde la caché (JSON) o lo extrae si no existe.\"\"\"\n",
    "    metadata_manager = MetadataManager(index, output_dir)\n",
    "    \n",
    "    if metadata_manager.exists():\n",
    "        chunks = metadata_manager.get(\"chunks\")\n",
    "        file_name = metadata_manager.get(\"fileName\")\n",
    "        if chunks and file_name == os.path.basename(pdf_path):\n",
    "            return chunks\n",
    "    \n",
    "    try:\n",
    "        pages_text = extract_text_from_pdf(pdf_path)\n",
    "        if pages_text:\n",
    "            metadata_manager.set(\"chunks\", pages_text)\n",
    "            metadata_manager.set(\"fileName\", os.path.basename(pdf_path))\n",
    "            metadata_manager.set(\"conversations\", [])\n",
    "        return pages_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error al extraer texto del PDF {pdf_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "async def get_conversation_from_chunk(index: int, output_dir: str, chunk: str):\n",
    "    \"\"\"Obtiene o genera una conversación para un fragmento de texto.\"\"\"\n",
    "    metadata_manager = MetadataManager(index, output_dir)\n",
    "    existing_conversations = metadata_manager.get(\"conversations\")\n",
    "    \n",
    "    for conv in existing_conversations:\n",
    "        if isinstance(conv, dict) and conv.get(\"source_chunk\") == chunk:\n",
    "            return conv\n",
    "    \n",
    "    try:\n",
    "        conversation = await generate_conversation(chunk)\n",
    "        if conversation:\n",
    "            conv_dict = conversation.model_dump()\n",
    "            conv_dict[\"source_chunk\"] = chunk\n",
    "            return conv_dict\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar conversación para fragmento en PDF #{index}: {e}\")\n",
    "        return None\n",
    "\n",
    "async def process_pdf(index: int, pdf_path: str, output_dir: str):\n",
    "    \"\"\"Procesa un PDF, genera conversaciones y las guarda en JSONL.\"\"\"\n",
    "    try:\n",
    "        pages_text = get_text_from_pdf(index, pdf_path, output_dir)\n",
    "        \n",
    "        if not pages_text:\n",
    "            print(f\"No se encontraron fragmentos de texto para el PDF #{index}: {pdf_path}\")\n",
    "            return\n",
    "        \n",
    "        data_dir = os.path.join(output_dir, \"data\")\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        jsonl_file = os.path.join(data_dir, f\"pdf_{index:04d}.jsonl\")\n",
    "        \n",
    "        tasks = [get_conversation_from_chunk(index, output_dir, fragment) \n",
    "                 for fragment in pages_text if len(fragment) > 20]\n",
    "        conversations = await tqdm_asyncio.gather(*tasks, desc=f\"Procesando PDF #{index} '{pdf_path}'\")\n",
    "        \n",
    "        valid_conversations = [conv for conv in conversations if conv is not None]\n",
    "        if valid_conversations:\n",
    "            # Guardar en JSONL\n",
    "            with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                output_str = \"\\n\".join(json.dumps({\"messages\":conv['messages'],\"topic\":conv['topic']}, ensure_ascii=False) for conv in valid_conversations)\n",
    "                f.write(output_str + \"\\n\")\n",
    "            \n",
    "            \n",
    "            metadata_manager = MetadataManager(index, output_dir)\n",
    "            metadata_manager.set(\"conversations\", valid_conversations)\n",
    "            metadata_manager.set(\"num_interactions\",len(valid_conversations))\n",
    "            total_messages = sum(len(conv['messages']) for conv in valid_conversations)\n",
    "            metadata_manager.set(\"num_messages\",total_messages)\n",
    "        else:\n",
    "            print(f\"No se generaron conversaciones para el PDF #{index}: {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el PDF {pdf_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fdbb014-2ca2-4f7f-bdfe-1430423e7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def process_pdf_wrapper(args):\n",
    "    index, pdf_path, output_dir = args\n",
    "    # Ejecutar la función asíncrona process_pdf dentro de un bucle de eventos\n",
    "    asyncio.run(process_pdf(index, pdf_path, output_dir))\n",
    "\n",
    "def generate(max_workers=8):\n",
    "    pdf_files = files\n",
    "    output_dir=\"outputs\"\n",
    "    output_folder_path=Path(output_dir)\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    print(f\"Generando Datasets\\nmax_workers={max_workers}\\n# Files: {len(pdf_files)}\")\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        list(tqdm(executor.map(process_pdf_wrapper, [(i, p, output_dir) for i, p in enumerate(pdf_files)]), total=len(pdf_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe45b6-1566-44ee-bd25-001e9f76ea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando Datasets\n",
      "max_workers=15\n",
      "# Files: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando PDF #5 'docs/Spanish-Lavado-de-Activos-Basado-en-el-Comercio-Indicadores-de-Riesgo.pdf.coredownload.inline.pdf':   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron fragmentos de texto para el PDF #13: docs/RESOLUCION UIF.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando PDF #5 'docs/Spanish-Lavado-de-Activos-Basado-en-el-Comercio-Indicadores-de-Riesgo.pdf.coredownload.inline.pdf': 100%|██████████| 12/12 [00:00<00:00, 336.52it/s]\n",
      "Procesando PDF #15 'docs/Modelo_de_Administracion_del_Riesgo_de_LAFT_y_Contrabando_web.pdf':   0%|          | 0/592 [00:00<?, ?it/s]221 [00:00<?, ?it/s]t/s]<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-57' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Procesando PDF #5 'docs/Spanish-Lavado-de-Activos-Basado-en-el-Comercio-Indicadores-de-Riesgo.pdf.coredownload.inline.pdf':   0%|          | 0/12 [38:16<?, ?it/s]\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-58' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-48' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-49' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-50' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-51' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-52' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-53' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-54' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-55' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-56' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-57' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Procesando PDF #5 'docs/Spanish-Lavado-de-Activos-Basado-en-el-Comercio-Indicadores-de-Riesgo.pdf.coredownload.inline.pdf':   0%|          | 0/12 [38:21<?, ?it/s]\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-58' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-48' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-49' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-50' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-51' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-52' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-53' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-54' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-55' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-56' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-57' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Procesando PDF #5 'docs/Spanish-Lavado-de-Activos-Basado-en-el-Comercio-Indicadores-de-Riesgo.pdf.coredownload.inline.pdf':   0%|          | 0/12 [38:23<?, ?it/s]\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-58' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-48' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-49' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-50' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-51' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-52' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-53' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-54' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-55' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-56' coro=<tqdm_asyncio.gather.<locals>.wrap_awaitable() done, defined at /workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py:75> exception=TypeError(\"object NoneType can't be used in 'await' expression\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/fine-tunning-models/.venv/lib/python3.11/site-packages/tqdm/asyncio.py\", line 76, in wrap_awaitable\n",
      "    return i, await f\n",
      "              ^^^^^^^\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "Procesando PDF #8 'docs/RML BANCO CENTRAL.pdf': 100%|██████████| 2/2 [01:25<00:00, 42.55s/it]t]df.coredownload.inline (1).pdf':  17%|█▋        | 2/12 [01:09<04:50, 29.05s/it]\n",
      "Procesando PDF #17 'docs/manual-para-la-gestion-de-riesgos-lavados-de-activos-y-financiacion-del-terrorismo.pdf':   0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando PDF #10 'docs/Riesgo de Crédito.pdf': 100%|██████████| 11/11 [04:00<00:00, 21.82s/it]].coredownload.inline (1).pdf':  92%|█████████▏| 11/12 [03:43<00:19, 19.30s/it]\n",
      "Procesando PDF #18 'docs/manual_riesgos_mercado_liquidez_9_jul_10.pdf':   0%|          | 0/56 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando PDF #6 'docs/Spanish-Lavado-de-Activos-Basado-en-el-Comercio-Indicadores-de-Riesgo.pdf.coredownload.inline (1).pdf': 100%|██████████| 12/12 [04:39<00:00, 23.31s/it]\n",
      "Procesando PDF #19 'docs/manual_operaciones_activas_contingentes_24_feb_17.pdf':   0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generando conversación con Ollama: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando PDF #9 'docs/RESUMEN-EJECUTIVO.pdf':  17%|█▋        | 5/30 [09:19<32:11, 77.27s/it] 1:45, 15.08s/it]  :53,  1.57s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a4ebf-86b7-4ce0-a89a-975ee4a86092",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1685376-51e6-4287-a74e-26a1e3deffb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4bf20d9d5d429a87a1522c0622cab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cc3b1f5a8d41188412819e28b55e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/96 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b78dc506ac400fbfcf72115ca01365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages', 'topic'],\n",
       "        num_rows: 664\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"./outputs/*.jsonl\")\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa783a63-83da-4cd0-97a3-dc50d15df2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0302c5a93ee748c19fce35827aaa637e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "151e67bb-0111-4991-b87d-e724b183ea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f927e39d7bc4dfc9d55557c21ac7edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2593e683346a4d229b5e9c6d5c0481b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdb167115d14860a59947184dcab9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0569c44f34e6422d9c78ce1f9e5eeba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1d7e93c0804ab8aab28fb1266739cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########|  270kB /  270kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2027803f4d423bb6cb7c5ceb339b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jeanmcm/b_risks/commit/13e6a6ad8f5d4eb1efc3bf36fe4e0b58c6e237fb', commit_message='Upload dataset', commit_description='', oid='13e6a6ad8f5d4eb1efc3bf36fe4e0b58c6e237fb', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jeanmcm/b_risks', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jeanmcm/b_risks'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"jeanmcm/b_risks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f0891",
   "metadata": {},
   "source": [
    "# Testing RAG with Open WebUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01ce0bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Respuesta en streaming:</b> El riesgo financiero se refiere a las posibles pérdidas o daños económicos que pueden afectar a una empresa, individuo u organización debido a sus actividades financieras. Esto puede incluir la incertidumbre sobre los rendimientos de los activos financieros, el valor de los bienes y servicios, o la capacidad de un individuo o organización para generar ingresos.\n",
       "\n",
       "En el contexto del sistema financiero, las instituciones deben conocer a fondo las características particulares de las actividades económicas de sus clientes y las operaciones que realizan para identificar y gestionar los riesgos financieros asociados. Esto es fundamental para prevenir la ocurrencia de incumplimientos en las regulaciones financieras y minimizar el impacto de cualquier pérdida o daño.\n",
       "\n",
       "Según el artículo 43 del \"Bsoft Documents\", las instituciones del sistema financiero deben contar con una unidad de cumplimiento dirigida por un oficial de cumplimiento, que debe tener formación profesional en áreas como administración, contaduría, derecho o economía. Este equipo es responsable de garantizar que las políticas y procedimientos financieros sean adecuados y cumplan con los requisitos legales.\n",
       "\n",
       "Por lo tanto, el riesgo financiero se considera un aspecto crítico para las instituciones del sistema financiero, ya que puede tener graves consecuencias en su estabilidad y solvencia. Es importante que estas entidades tomen medidas proactivas para identificar, evaluar y gestionar los riesgos financieros asociados con sus actividades y operaciones.\n",
       "\n",
       "No se incluye ninguna cita porque no hay un id atributo en el source tag correspondiente a esta información, pero la respuesta se basa en el contexto proporcionado.."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "url = \"https://vwlppjjfa98c9x-8080.proxy.runpod.net\"\n",
    "api_key =\"sk-05568562f28844fe997cadf960a346cd\"\n",
    "\n",
    "messages =  [{\"role\": \"user\", \"content\": \"Que es el Riesgo Financiero?\"}]\n",
    "\n",
    "try:\n",
    "    # Realizar la solicitud con stream=True\n",
    "    with requests.post(f\"{url}/api/chat/completions\", stream=True,headers={\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    },json={\n",
    "      \"model\":\"bosft-riesgos-rag-model\",\n",
    "      \"messages\":messages,\n",
    "      \"stream\":True\n",
    "      }) as response:\n",
    "        response.raise_for_status()\n",
    "        # Variable para almacenar la salida acumulada\n",
    "        accumulated_output = \"\"\n",
    "\n",
    "        # Iterar sobre las líneas de la respuesta\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                # Decodificar la línea\n",
    "                decoded_line = line.decode('utf-8').strip()\n",
    "                # Si la línea comienza con \"data:\", extraer el contenido\n",
    "                if decoded_line.startswith(\"data:\"):\n",
    "                    decoded_line = decoded_line[5:].strip()  # Quitar \"data: \"\n",
    "\n",
    "                # Ignorar líneas vacías o marcadores de fin como \"[DONE]\"\n",
    "                if not decoded_line or decoded_line == \"[DONE]\" :\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    # Parsear si es JSON\n",
    "                    data = json.loads(decoded_line)\n",
    "                    if \"choices\" not in data: continue\n",
    "                    \n",
    "                    delta = data['choices'][0]['delta']\n",
    "                    if \"content\" in delta: new_data = delta['content']\n",
    "                except json.JSONDecodeError:\n",
    "                    # Si no es JSON, usar la línea como texto\n",
    "                    new_data = decoded_line\n",
    "\n",
    "                # Acumular y mostrar la salida dinámicamente\n",
    "                if new_data:\n",
    "                    accumulated_output += new_data\n",
    "                    # Limpiar la salida anterior y mostrar la nueva\n",
    "                    clear_output(wait=True)\n",
    "                    display(HTML(f\"<b>Respuesta en streaming:</b> {accumulated_output}\"))\n",
    "                    time.sleep(0.1)  # Pequeña pausa para visibilidad\n",
    "                    \n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\\nError en la solicitud: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64806a-ac56-417a-8dd9-175c3a8447a1",
   "metadata": {},
   "source": [
    "# Testing with Flowise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cb1c0-bb15-4c97-9e0c-0156e8b90df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
