{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8864c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (1.98.0)\n",
      "Collecting ollama\n",
      "  Using cached ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\desktop\\dev\\ollama\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "10eeda80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "22c152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class FormatItem(BaseModel):\n",
    "    prompt: str\n",
    "    completion:str\n",
    "class FormatList(BaseModel):\n",
    "    dataset:list[FormatItem]\n",
    "\n",
    "\n",
    "def generate_system_prompt(previous_prompts:list[str] = []):\n",
    "    content = f\"\"\"\n",
    "            You are an assistant with knowledge of datasets to be used as fine-tuning. The user provides you with a topic and you return a list of questions and answers or a request/completion about the topic. The data you return is intended for fine-tuning LLM. You return concise and understandable questions and answers. You take into account the TOPIC that the user provides you. You return what is related to the TOPIC.\n",
    "            \n",
    "            INSTRUCTIONS:\n",
    "            - YOU NEED TO GENERATE MORE THAN 10 or 20 PROMPT/COMPLETION \n",
    "            - GENERATE COMPLETION DETAILED AND SPECIFIED TO REINFORCE DATA TRAINER\n",
    "            \n",
    "            <context>\n",
    "            YOU NEED TO AVOID TO REPEAT THE SAME PROMPTS, THERE IS THE NEXT PROMPTS, TRY TO GENERATE DIFFERENT PROMPT/COMPLETION,\n",
    "            TOTAL PREVIOUS PROMPTS: {len(previous_prompts)}\n",
    "            PREVIOUS PROMPTS: {', '.join(previous_prompts)}\n",
    "            TRY TO GENERATE DIFFERENT PROMPTS/COMPLETIONS, BASED IN THE PREVIOUS PROMPTS, GENERATE DIFFERENT PROMPTS/COMPLETION BASE ON TOPIC THAT USER PROVIDES YOU\n",
    "            </context>\n",
    "            \"\"\"\n",
    "    return content\n",
    "\n",
    "def generate_input(previous_prompts:list[str] = [], topic:str=''):\n",
    "    system = generate_system_prompt(previous_prompts)\n",
    "    input = [{\n",
    "            \"role\":\"assistant\",\n",
    "            \"content\":system\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":f\"TOPIC: {topic}\"\n",
    "        }]\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "816fb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from ollama import AsyncClient,ChatResponse\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "ollama_client = AsyncClient(\n",
    "  host='https://zk8ufz7qvz0kxi-11434.proxy.runpod.net/',\n",
    ")\n",
    "\n",
    "\n",
    "openai_client = AsyncOpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "async def call_ollama(messages) -> Optional[FormatList]:\n",
    "  try:\n",
    "    response: ChatResponse = await ollama_client.chat(\n",
    "    model='llama3.1:8b',\n",
    "    messages=messages,\n",
    "    format=FormatList.model_json_schema()\n",
    "    )\n",
    "    format = FormatList.model_validate_json(response.message.content)\n",
    "\n",
    "    return format\n",
    "  except Exception as e:\n",
    "    print(f\"Ollama error: {e}\")\n",
    "    return None\n",
    "    \n",
    "    \n",
    "async def call_openai(messages) -> Optional[FormatList]:\n",
    "  try:\n",
    "    response = await openai_client.responses.parse(\n",
    "      model=\"gpt-4o-mini\",\n",
    "      input=messages,\n",
    "      text_format=FormatList  \n",
    "    )\n",
    "    return response.output_parsed\n",
    "  except Exception as e:\n",
    "    print(f\"OpenAI Error: {e}\")\n",
    "    return None\n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2d08180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "async def generate_qa(previous_prompts:list[str] = [], topic:str =\"\")->list[FormatItem]:\n",
    "    \n",
    "    messages = generate_input(previous_prompts,topic)\n",
    "    \n",
    "    llama_task = call_ollama(messages)\n",
    "    openai_task = call_openai(messages)\n",
    "    \n",
    "    responses = await asyncio.gather(llama_task,openai_task, return_exceptions=True)\n",
    "    \n",
    "    qa = [item for items in responses for item in items.model_dump()['dataset']]\n",
    "    \n",
    "    \n",
    "    return qa\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "80ea2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_name = \"output.csv\"\n",
    "async def generate():\n",
    "    previous_prompts = []\n",
    "    topic = \"Riesgos no Financieros\"\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            df_existing = pd.read_csv(file_name)\n",
    "            # Verificar si la columna 'prompts' existe y extraerla\n",
    "            if 'prompt' in df_existing.columns:\n",
    "                previous_prompts = df_existing['prompt'].tolist()\n",
    "            else:\n",
    "                print(\"Advertencia: La columna 'prompt' no existe en el archivo CSV.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo CSV: {e}\")\n",
    "    else:\n",
    "        print(f\"El archivo {file_name} no existe, se crear√° uno nuevo.\")\n",
    "        \n",
    "    n = 5    \n",
    "\n",
    "    for _ in range(n):\n",
    "        response = await generate_qa(previous_prompts,topic)\n",
    "        \n",
    "        r_df = pd.DataFrame(response)\n",
    "        \n",
    "        print(f\"Generated P/C: {len(r_df)}\")\n",
    "        \n",
    "        new_prompts = r_df['prompt'].to_list()\n",
    "        previous_prompts.extend(new_prompts)\n",
    "        \n",
    "        if os.path.exists(file_name):\n",
    "            r_df.to_csv(file_name, sep=\",\", index=False, mode='a', header=False)\n",
    "        else:\n",
    "            r_df.to_csv(file_name, sep=\",\", index=False, mode='w')\n",
    "            \n",
    "    print(f\"Saved to {file_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7a30a97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated P/C: 28\n",
      "Generated P/C: 31\n",
      "Generated P/C: 32\n",
      "Generated P/C: 47\n",
      "Generated P/C: 29\n",
      "Saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "await generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b6a005de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cfg = pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e368c8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¬øCu√°les son los principales tipos de riesgos n...</td>\n",
       "      <td>Los principales tipos de riesgos no financiero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¬øC√≥mo se pueden mitigar los riesgos no financi...</td>\n",
       "      <td>Para mitigar riesgos no financieros, se pueden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¬øPor qu√© es importante considerar los riesgos ...</td>\n",
       "      <td>Considerar riesgos no financieros en la planif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>¬øQu√© papel juega la cultura organizacional en ...</td>\n",
       "      <td>La cultura organizacional desempe√±a un papel f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¬øQu√© herramientas podr√≠an utilizarse para eval...</td>\n",
       "      <td>Las herramientas que se pueden utilizar para e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>¬øCu√°les son las diferencias clave entre riesgo...</td>\n",
       "      <td>Los riesgos financieros est√°n relacionados con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>¬øPor qu√© es relevante considerar los riesgos n...</td>\n",
       "      <td>Incluir riesgos no financieros en informes fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>¬øQu√© tecnolog√≠a puede ayudar en la detecci√≥n d...</td>\n",
       "      <td>Herramientas de inteligencia artificial y apre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>¬øQu√© rol juega la educaci√≥n continua en la ges...</td>\n",
       "      <td>La educaci√≥n continua asegura que los empleado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>¬øC√≥mo pueden las empresas utilizar la gesti√≥n ...</td>\n",
       "      <td>La gesti√≥n de riesgos no financieros puede cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    ¬øCu√°les son los principales tipos de riesgos n...   \n",
       "1    ¬øC√≥mo se pueden mitigar los riesgos no financi...   \n",
       "2    ¬øPor qu√© es importante considerar los riesgos ...   \n",
       "3    ¬øQu√© papel juega la cultura organizacional en ...   \n",
       "4    ¬øQu√© herramientas podr√≠an utilizarse para eval...   \n",
       "..                                                 ...   \n",
       "231  ¬øCu√°les son las diferencias clave entre riesgo...   \n",
       "232  ¬øPor qu√© es relevante considerar los riesgos n...   \n",
       "233  ¬øQu√© tecnolog√≠a puede ayudar en la detecci√≥n d...   \n",
       "234  ¬øQu√© rol juega la educaci√≥n continua en la ges...   \n",
       "235  ¬øC√≥mo pueden las empresas utilizar la gesti√≥n ...   \n",
       "\n",
       "                                            completion  \n",
       "0    Los principales tipos de riesgos no financiero...  \n",
       "1    Para mitigar riesgos no financieros, se pueden...  \n",
       "2    Considerar riesgos no financieros en la planif...  \n",
       "3    La cultura organizacional desempe√±a un papel f...  \n",
       "4    Las herramientas que se pueden utilizar para e...  \n",
       "..                                                 ...  \n",
       "231  Los riesgos financieros est√°n relacionados con...  \n",
       "232  Incluir riesgos no financieros en informes fin...  \n",
       "233  Herramientas de inteligencia artificial y apre...  \n",
       "234  La educaci√≥n continua asegura que los empleado...  \n",
       "235  La gesti√≥n de riesgos no financieros puede cre...  \n",
       "\n",
       "[236 rows x 2 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28689cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\_login.py:340\u001b[39m, in \u001b[36mnotebook_login\u001b[39m\u001b[34m(new_session, write_permission)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipywidgets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwidgets\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHUGGING_FACE_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[39m, in \u001b[36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m         message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:31\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     33\u001b[39m args_msg = [\n\u001b[32m     34\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     36\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\_login.py:128\u001b[39m, in \u001b[36mlogin\u001b[39m\u001b[34m(token, add_to_git_credential, new_session, write_permission)\u001b[39m\n\u001b[32m    126\u001b[39m     _login(token, add_to_git_credential=add_to_git_credential)\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_session\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    130\u001b[39m     interpreter_login(new_session=new_session)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[39m, in \u001b[36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m         message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:31\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     33\u001b[39m args_msg = [\n\u001b[32m     34\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     36\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\_login.py:343\u001b[39m, in \u001b[36mnotebook_login\u001b[39m\u001b[34m(new_session, write_permission)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    346\u001b[39m     )\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_session \u001b[38;5;129;01mand\u001b[39;00m get_token() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mUser is already logged in.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "login(os.environ.get(\"HUGGING_FACE_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e62b13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "train_dataset = Dataset.from_pandas(cfg)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset, \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "52b2d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 49.55ba/s]\n",
      "Uploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.64s/ shards]\n",
      "c:\\Users\\ASUS\\Desktop\\dev\\ollama\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub\\datasets--jeanmcm--sample. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jeanmcm/sample/commit/34dcb9f6cf796d237f06b627cc1bd398669d0514', commit_message='Upload dataset', commit_description='', oid='34dcb9f6cf796d237f06b627cc1bd398669d0514', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jeanmcm/sample', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jeanmcm/sample'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"jeanmcm/sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe0270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
